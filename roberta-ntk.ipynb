{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport optuna\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor, Pool, CatBoost\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n                                      ReduceLROnPlateau)\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-31T11:20:08.140699Z","iopub.execute_input":"2021-05-31T11:20:08.140992Z","iopub.status.idle":"2021-05-31T11:20:20.776458Z","shell.execute_reply.started":"2021-05-31T11:20:08.140921Z","shell.execute_reply":"2021-05-31T11:20:20.775578Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\ntrain_data = train_data[train_data[\"target\"] != 0]\n\ntarget = train_data['target'].to_numpy()\n\n#for kfold  \nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:20:20.778328Z","iopub.execute_input":"2021-05-31T11:20:20.778647Z","iopub.status.idle":"2021-05-31T11:20:20.895494Z","shell.execute_reply.started":"2021-05-31T11:20:20.778617Z","shell.execute_reply":"2021-05-31T11:20:20.894812Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:20:20.897400Z","iopub.execute_input":"2021-05-31T11:20:20.897643Z","iopub.status.idle":"2021-05-31T11:20:20.908102Z","shell.execute_reply.started":"2021-05-31T11:20:20.897618Z","shell.execute_reply":"2021-05-31T11:20:20.907341Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(nn.Module):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)  \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:20:20.909609Z","iopub.execute_input":"2021-05-31T11:20:20.910001Z","iopub.status.idle":"2021-05-31T11:20:20.916906Z","shell.execute_reply.started":"2021-05-31T11:20:20.909962Z","shell.execute_reply":"2021-05-31T11:20:20.915923Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.efrom_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df,tokenizer,config['max_len'])\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:,0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:20:20.919231Z","iopub.execute_input":"2021-05-31T11:20:20.919565Z","iopub.status.idle":"2021-05-31T11:20:20.929012Z","shell.execute_reply.started":"2021-05-31T11:20:20.919529Z","shell.execute_reply":"2021-05-31T11:20:20.928304Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  get_embeddings(train_data,'../input/roberta/roberta-base/roberta-base')\ntest_embeddings1 = get_embeddings(test_data,'../input/roberta/roberta-base/roberta-base')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:20:31.496498Z","iopub.execute_input":"2021-05-31T11:20:31.496807Z","iopub.status.idle":"2021-05-31T11:21:12.335875Z","shell.execute_reply.started":"2021-05-31T11:20:31.496780Z","shell.execute_reply":"2021-05-31T11:21:12.334860Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"23it [00:22,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"1it [00:00,  5.05it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_embeddings2 =  get_embeddings(train_data,'../input/robertalargeft/roberta-large-ft')\ntest_embeddings2 = get_embeddings(test_data,'../input/robertalargeft/roberta-large-ft')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:21:30.570905Z","iopub.execute_input":"2021-05-31T11:21:30.571254Z","iopub.status.idle":"2021-05-31T11:21:37.667561Z","shell.execute_reply.started":"2021-05-31T11:21:30.571222Z","shell.execute_reply":"2021-05-31T11:21:37.665204Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:110] . file in archive is not in a subdirectory: model0.bin","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-553eb8f8e740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_embeddings2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../input/robertalargeft/roberta-large-ft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_embeddings2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../input/robertalargeft/roberta-large-ft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-632e3c20f45a>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(df, path, plot_losses, verbose)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             return MODEL_MAPPING[type(config)].from_pretrained(\n\u001b[0;32m--> 815\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m             )\n\u001b[1;32m    817\u001b[0m         raise ValueError(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 raise OSError(\n\u001b[0;32m-> 1065\u001b[0;31m                     \u001b[0;34mf\"Unable to load weights from pytorch checkpoint file for '{pretrained_model_name_or_path}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m                     \u001b[0;34mf\"at '{resolved_archive_file}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file for '../input/robertalargeft/roberta-large-ft' at '../input/robertalargeft/roberta-large-ft/pytorch_model.bin'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "],"ename":"OSError","evalue":"Unable to load weights from pytorch checkpoint file for '../input/robertalargeft/roberta-large-ft' at '../input/robertalargeft/roberta-large-ft/pytorch_model.bin'If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. ","output_type":"error"}]},{"cell_type":"markdown","source":"## Neural Tangent Kernel (NTK)","metadata":{}},{"cell_type":"code","source":"!pip install ../input/roberta/frozendict-2.0.2-py3-none-any.whl\n!pip install ../input/roberta/neural_tangents-0.3.6-py2.py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:03:23.101724Z","iopub.execute_input":"2021-05-29T10:03:23.102111Z","iopub.status.idle":"2021-05-29T10:04:15.663737Z","shell.execute_reply.started":"2021-05-29T10:03:23.102066Z","shell.execute_reply":"2021-05-29T10:04:15.662741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jax import random\nfrom neural_tangents import stax\nimport neural_tangents as nt\n\ndef get_preds_svm(X,y,X_test,bins=bins,nfolds=5):\n    kfold = StratifiedKFold(n_splits=nfolds)\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n\n        ResBlock = stax.serial(\n                        stax.FanOut(2),\n                        stax.parallel(\n                            stax.serial(\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                            ),\n                            stax.Identity(),\n                        ),\n                        stax.FanInSum()\n                    )\n\n        init_fn, apply_fn, kernel_fn = stax.serial(\n                stax.Dense(1, W_std=1.0, b_std=0),\n                ResBlock, ResBlock, stax.Erf(),\n                stax.Dense(1, W_std=2.5, b_std=0.1)\n        )\n\n        key = random.PRNGKey(10)\n        _, params = init_fn(key, input_shape=X_train.shape)\n        predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn,\n                                                                  X_train,\n                                                                  y_train[:,np.newaxis],\n                                                                  diag_reg=1e-1,\n                                                                  lr=1)\n        prediction = predict_fn(x_test=X_valid, get='nngp', t=None)#model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += predict_fn(x_test=X_test, get='nngp', t=None)#model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:04:15.667582Z","iopub.execute_input":"2021-05-29T10:04:15.667895Z","iopub.status.idle":"2021-05-29T10:04:16.3254Z","shell.execute_reply.started":"2021-05-29T10:04:15.667863Z","shell.execute_reply":"2021-05-29T10:04:16.324414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\nsvm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:04:16.326861Z","iopub.execute_input":"2021-05-29T10:04:16.327418Z","iopub.status.idle":"2021-05-29T10:07:32.02872Z","shell.execute_reply.started":"2021-05-29T10:04:16.327389Z","shell.execute_reply":"2021-05-29T10:07:32.027843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = (svm_preds1[:,0] + svm_preds2[:,0])/2","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:15:31.335546Z","iopub.execute_input":"2021-05-29T10:15:31.335921Z","iopub.status.idle":"2021-05-29T10:15:31.343422Z","shell.execute_reply.started":"2021-05-29T10:15:31.335884Z","shell.execute_reply":"2021-05-29T10:15:31.342604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = preds\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:15:47.967515Z","iopub.execute_input":"2021-05-29T10:15:47.96783Z","iopub.status.idle":"2021-05-29T10:15:47.980089Z","shell.execute_reply.started":"2021-05-29T10:15:47.967799Z","shell.execute_reply":"2021-05-29T10:15:47.979255Z"},"trusted":true},"execution_count":null,"outputs":[]}]}