{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crazy-height",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:11.160648Z",
     "iopub.status.busy": "2021-05-29T11:40:11.160045Z",
     "iopub.status.idle": "2021-05-29T11:40:22.507354Z",
     "shell.execute_reply": "2021-05-29T11:40:22.506447Z",
     "shell.execute_reply.started": "2021-05-29T10:00:32.181857Z"
    },
    "papermill": {
     "duration": 11.390295,
     "end_time": "2021-05-29T11:40:22.507516",
     "exception": false,
     "start_time": "2021-05-29T11:40:11.117221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor, Pool, CatBoost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n",
    "                                      ReduceLROnPlateau)\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blocked-alliance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:22.573941Z",
     "iopub.status.busy": "2021-05-29T11:40:22.573417Z",
     "iopub.status.idle": "2021-05-29T11:40:22.668750Z",
     "shell.execute_reply": "2021-05-29T11:40:22.668249Z",
     "shell.execute_reply.started": "2021-05-29T10:00:32.655541Z"
    },
    "papermill": {
     "duration": 0.131618,
     "end_time": "2021-05-29T11:40:22.668865",
     "exception": false,
     "start_time": "2021-05-29T11:40:22.537247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "train_data = train_data[train_data[\"target\"] != 0]\n",
    "\n",
    "target = train_data['target'].to_numpy()\n",
    "\n",
    "#for kfold  \n",
    "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
    "bins = train_data.bins.to_numpy()\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepting-brick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:22.733108Z",
     "iopub.status.busy": "2021-05-29T11:40:22.732482Z",
     "iopub.status.idle": "2021-05-29T11:40:22.738207Z",
     "shell.execute_reply": "2021-05-29T11:40:22.737782Z",
     "shell.execute_reply.started": "2021-05-29T10:00:32.745839Z"
    },
    "papermill": {
     "duration": 0.040434,
     "end_time": "2021-05-29T11:40:22.738318",
     "exception": false,
     "start_time": "2021-05-29T11:40:22.697884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-nitrogen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:22.803232Z",
     "iopub.status.busy": "2021-05-29T11:40:22.802457Z",
     "iopub.status.idle": "2021-05-29T11:40:22.805044Z",
     "shell.execute_reply": "2021-05-29T11:40:22.804639Z",
     "shell.execute_reply.started": "2021-05-29T10:00:32.824794Z"
    },
    "papermill": {
     "duration": 0.037679,
     "end_time": "2021-05-29T11:40:22.805151",
     "exception": false,
     "start_time": "2021-05-29T11:40:22.767472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(nn.Module):\n",
    "    def __init__(self,df,tokenizer,max_len=128):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)  \n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eleven-jumping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:22.871172Z",
     "iopub.status.busy": "2021-05-29T11:40:22.870427Z",
     "iopub.status.idle": "2021-05-29T11:40:22.872626Z",
     "shell.execute_reply": "2021-05-29T11:40:22.873065Z",
     "shell.execute_reply.started": "2021-05-29T10:00:32.902812Z"
    },
    "papermill": {
     "duration": 0.03921,
     "end_time": "2021-05-29T11:40:22.873188",
     "exception": false,
     "start_time": "2021-05-29T11:40:22.833978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    MODEL_PATH = path\n",
    "    model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    ds = CLRPDataset(df,tokenizer,config['max_len'])\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs[0][:,0].detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "awful-yesterday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:40:22.984945Z",
     "iopub.status.busy": "2021-05-29T11:40:22.984354Z",
     "iopub.status.idle": "2021-05-29T11:43:15.790180Z",
     "shell.execute_reply": "2021-05-29T11:43:15.789713Z",
     "shell.execute_reply.started": "2021-05-29T10:00:33.444575Z"
    },
    "papermill": {
     "duration": 172.888018,
     "end_time": "2021-05-29T11:43:15.790315",
     "exception": false,
     "start_time": "2021-05-29T11:40:22.902297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:22,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:21,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf3 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:21,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf3 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf4 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf4 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf5 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:21,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf5 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  4.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(train_data,'../input/modelf1')\n",
    "test_embeddings1 = get_embeddings(test_data,'../input/modelf1')\n",
    "\n",
    "train_embeddings2 =  get_embeddings(train_data,'../input/modelf2')\n",
    "test_embeddings2 = get_embeddings(test_data,'../input/modelf2')\n",
    "\n",
    "train_embeddings3 =  get_embeddings(train_data,'../input/modelf3')\n",
    "test_embeddings3 = get_embeddings(test_data,'../input/modelf3')\n",
    "\n",
    "train_embeddings4 =  get_embeddings(train_data,'../input/modelf4')\n",
    "test_embeddings4 = get_embeddings(test_data,'../input/modelf4')\n",
    "\n",
    "train_embeddings5 =  get_embeddings(train_data,'../input/modelf5')\n",
    "test_embeddings5 = get_embeddings(test_data,'../input/modelf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-brother",
   "metadata": {
    "papermill": {
     "duration": 0.069041,
     "end_time": "2021-05-29T11:43:15.929223",
     "exception": false,
     "start_time": "2021-05-29T11:43:15.860182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## neural tangent kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integrated-lafayette",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:43:16.074014Z",
     "iopub.status.busy": "2021-05-29T11:43:16.073413Z",
     "iopub.status.idle": "2021-05-29T11:44:08.625951Z",
     "shell.execute_reply": "2021-05-29T11:44:08.625474Z",
     "shell.execute_reply.started": "2021-05-29T10:03:23.102066Z"
    },
    "papermill": {
     "duration": 52.627695,
     "end_time": "2021-05-29T11:44:08.626095",
     "exception": false,
     "start_time": "2021-05-29T11:43:15.998400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/roberta/frozendict-2.0.2-py3-none-any.whl\r\n",
      "Installing collected packages: frozendict\r\n",
      "Successfully installed frozendict-2.0.2\r\n",
      "Processing /kaggle/input/roberta/neural_tangents-0.3.6-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: frozendict>=1.2 in /opt/conda/lib/python3.7/site-packages (from neural-tangents==0.3.6) (2.0.2)\r\n",
      "Requirement already satisfied: jax>=0.1.77 in /opt/conda/lib/python3.7/site-packages (from neural-tangents==0.3.6) (0.2.12)\r\n",
      "Requirement already satisfied: numpy>=1.12 in /opt/conda/lib/python3.7/site-packages (from jax>=0.1.77->neural-tangents==0.3.6) (1.19.5)\r\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/lib/python3.7/site-packages (from jax>=0.1.77->neural-tangents==0.3.6) (3.3.0)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from jax>=0.1.77->neural-tangents==0.3.6) (0.12.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py->jax>=0.1.77->neural-tangents==0.3.6) (1.15.0)\r\n",
      "Installing collected packages: neural-tangents\r\n",
      "Successfully installed neural-tangents-0.3.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/roberta/frozendict-2.0.2-py3-none-any.whl\n",
    "!pip install ../input/roberta/neural_tangents-0.3.6-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "better-moment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:44:08.783478Z",
     "iopub.status.busy": "2021-05-29T11:44:08.782430Z",
     "iopub.status.idle": "2021-05-29T11:44:09.383523Z",
     "shell.execute_reply": "2021-05-29T11:44:09.383049Z",
     "shell.execute_reply.started": "2021-05-29T10:04:15.667863Z"
    },
    "papermill": {
     "duration": 0.685365,
     "end_time": "2021-05-29T11:44:09.383651",
     "exception": false,
     "start_time": "2021-05-29T11:44:08.698286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax import random\n",
    "from neural_tangents import stax\n",
    "import neural_tangents as nt\n",
    "\n",
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n",
    "    kfold = StratifiedKFold(n_splits=nfolds)\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "        ResBlock = stax.serial(\n",
    "                        stax.FanOut(2),\n",
    "                        stax.parallel(\n",
    "                            stax.serial(\n",
    "                                stax.Erf(),\n",
    "                                stax.Dense(1, W_std=1.25, b_std=0.0),\n",
    "                                stax.Erf(),\n",
    "                                stax.Dense(1, W_std=1.25, b_std=0.0),\n",
    "                                stax.Erf(),\n",
    "                                stax.Dense(1, W_std=1.25, b_std=0.0),\n",
    "                            ),\n",
    "                            stax.Identity(),\n",
    "                        ),\n",
    "                        stax.FanInSum()\n",
    "                    )\n",
    "\n",
    "        init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "                stax.Dense(1, W_std=1.0, b_std=0),\n",
    "                ResBlock, ResBlock, stax.Erf(),\n",
    "                stax.Dense(1, W_std=2.5, b_std=0.1)\n",
    "        )\n",
    "\n",
    "        key = random.PRNGKey(10)\n",
    "        _, params = init_fn(key, input_shape=X_train.shape)\n",
    "        predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn,\n",
    "                                                                  X_train,\n",
    "                                                                  y_train[:,np.newaxis],\n",
    "                                                                  diag_reg=1e-1,\n",
    "                                                                  lr=1)\n",
    "        prediction = predict_fn(x_test=X_valid, get='nngp', t=None)#model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += predict_fn(x_test=X_test, get='nngp', t=None)#model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parliamentary-creek",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:44:09.533626Z",
     "iopub.status.busy": "2021-05-29T11:44:09.532969Z",
     "iopub.status.idle": "2021-05-29T11:47:29.027012Z",
     "shell.execute_reply": "2021-05-29T11:47:29.027556Z",
     "shell.execute_reply.started": "2021-05-29T10:04:16.327389Z"
    },
    "papermill": {
     "duration": 199.571746,
     "end_time": "2021-05-29T11:47:29.027768",
     "exception": false,
     "start_time": "2021-05-29T11:44:09.456022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.3533070781162649\n",
      "Fold 1 , rmse score: 0.3507230838219165\n",
      "Fold 2 , rmse score: 0.3397112689980713\n",
      "Fold 3 , rmse score: 0.3753341700861172\n",
      "Fold 4 , rmse score: 0.36457406824600735\n",
      "mean rmse 0.35672993385367546\n",
      "Fold 0 , rmse score: 0.3664070926170059\n",
      "Fold 1 , rmse score: 0.36622260558839487\n",
      "Fold 2 , rmse score: 0.3406317445293064\n",
      "Fold 3 , rmse score: 0.36522604334069825\n",
      "Fold 4 , rmse score: 0.37621146467913735\n",
      "mean rmse 0.3629397901509085\n",
      "Fold 0 , rmse score: 0.32081083473943894\n",
      "Fold 1 , rmse score: 0.30368101359758487\n",
      "Fold 2 , rmse score: 0.257158602494956\n",
      "Fold 3 , rmse score: 0.3019013086614748\n",
      "Fold 4 , rmse score: 0.308016349598385\n",
      "mean rmse 0.2983136218183679\n",
      "Fold 0 , rmse score: 0.42375648572370384\n",
      "Fold 1 , rmse score: 0.41970820210181\n",
      "Fold 2 , rmse score: 0.37810095317003733\n",
      "Fold 3 , rmse score: 0.41231838465252707\n",
      "Fold 4 , rmse score: 0.4364009493152341\n",
      "mean rmse 0.4140569949926626\n",
      "Fold 0 , rmse score: 0.35939226525594736\n",
      "Fold 1 , rmse score: 0.3635584373235376\n",
      "Fold 2 , rmse score: 0.3464874267879232\n",
      "Fold 3 , rmse score: 0.34267165190274795\n",
      "Fold 4 , rmse score: 0.35816367325575454\n",
      "mean rmse 0.35405469090518216\n"
     ]
    }
   ],
   "source": [
    "svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n",
    "svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n",
    "svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n",
    "svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n",
    "svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-simple",
   "metadata": {
    "papermill": {
     "duration": 0.078483,
     "end_time": "2021-05-29T11:47:29.186246",
     "exception": false,
     "start_time": "2021-05-29T11:47:29.107763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Topological Features + LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sixth-leather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:29.389966Z",
     "iopub.status.busy": "2021-05-29T11:47:29.349704Z",
     "iopub.status.idle": "2021-05-29T11:47:41.046278Z",
     "shell.execute_reply": "2021-05-29T11:47:41.046717Z",
     "shell.execute_reply.started": "2021-05-29T10:07:32.03136Z"
    },
    "papermill": {
     "duration": 11.781682,
     "end_time": "2021-05-29T11:47:41.046869",
     "exception": false,
     "start_time": "2021-05-29T11:47:29.265187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Processing /kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from pyflagser) (1.5.4)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from pyflagser) (1.19.5)\r\n",
      "Installing collected packages: pyflagser\r\n",
      "Successfully installed pyflagser-0.4.4\r\n",
      "Looking in links: file:///kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Processing /kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: pyflagser>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.4.4)\r\n",
      "Requirement already satisfied: plotly>=4.8.2 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (4.14.3)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.5.4)\r\n",
      "Requirement already satisfied: python-igraph>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.9.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.19.5)\r\n",
      "Requirement already satisfied: scikit-learn>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.24.1)\r\n",
      "Requirement already satisfied: joblib>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.0.1)\r\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (7.6.3)\r\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (7.22.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.0.5)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (1.0.0)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.1.2)\r\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.5.0)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (3.5.1)\r\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.1)\r\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.1.12)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.4.2)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (2.8.1)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.5)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.8.0)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (3.0.18)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.18.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.8.1)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (0.2.0)\r\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (4.7.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.2.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (20.3.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (0.17.3)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (1.15.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.0)\r\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.8.2->giotto-tda) (1.3.3)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.5)\r\n",
      "Requirement already satisfied: texttable>=1.6.2 in /opt/conda/lib/python3.7/site-packages (from python-igraph>=0.8.2->giotto-tda) (1.6.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.1->giotto-tda) (2.1.0)\r\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (6.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.11.3)\r\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.9.0)\r\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (20.1.0)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (6.0.7)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.9.3)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (22.0.3)\r\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.5.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (2.8.1)\r\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.14.5)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.20)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.1.1)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.4.4)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.1.2)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.8.4)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.4.2)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.5.3)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (3.3.0)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.7.1)\r\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.3)\r\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.10)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.4.3)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.5.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (20.9)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.4.7)\r\n",
      "Installing collected packages: giotto-tda\r\n",
      "Successfully installed giotto-tda-0.4.0\r\n"
     ]
    }
   ],
   "source": [
    "# thinking about augmentation\n",
    "# !pip install nlpaug --no-index --find-links=file:///kaggle/input/roberta/nlpaug-1.1.3-py3-none-any.whl\n",
    "\n",
    "#library for topological data analysis\n",
    "!pip install pyflagser --no-index --find-links=file:///kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\n",
    "!pip install giotto-tda --no-index --find-links=file:///kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cooperative-problem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:41.224677Z",
     "iopub.status.busy": "2021-05-29T11:47:41.224005Z",
     "iopub.status.idle": "2021-05-29T11:47:41.227340Z",
     "shell.execute_reply": "2021-05-29T11:47:41.226877Z",
     "shell.execute_reply.started": "2021-05-29T10:07:43.914471Z"
    },
    "papermill": {
     "duration": 0.09568,
     "end_time": "2021-05-29T11:47:41.227456",
     "exception": false,
     "start_time": "2021-05-29T11:47:41.131776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# some gradient boosting algos\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool, CatBoost\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n",
    "                                      ReduceLROnPlateau)\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n",
    "\n",
    "## Possible augmentation strategies\n",
    "#import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spectacular-morning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:41.400643Z",
     "iopub.status.busy": "2021-05-29T11:47:41.399594Z",
     "iopub.status.idle": "2021-05-29T11:47:41.442360Z",
     "shell.execute_reply": "2021-05-29T11:47:41.441888Z",
     "shell.execute_reply.started": "2021-05-29T10:07:43.927174Z"
    },
    "papermill": {
     "duration": 0.1316,
     "end_time": "2021-05-29T11:47:41.442479",
     "exception": false,
     "start_time": "2021-05-29T11:47:41.310879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "train_data = train_data[train_data[\"target\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "approximate-armenia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:41.616763Z",
     "iopub.status.busy": "2021-05-29T11:47:41.615979Z",
     "iopub.status.idle": "2021-05-29T11:47:41.621450Z",
     "shell.execute_reply": "2021-05-29T11:47:41.621050Z",
     "shell.execute_reply.started": "2021-05-29T10:07:43.981325Z"
    },
    "papermill": {
     "duration": 0.09518,
     "end_time": "2021-05-29T11:47:41.621559",
     "exception": false,
     "start_time": "2021-05-29T11:47:41.526379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = train_data['target'].to_numpy()\n",
    "\n",
    "#for kfold  \n",
    "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fabulous-elite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:41.795632Z",
     "iopub.status.busy": "2021-05-29T11:47:41.794726Z",
     "iopub.status.idle": "2021-05-29T11:47:41.797593Z",
     "shell.execute_reply": "2021-05-29T11:47:41.797158Z",
     "shell.execute_reply.started": "2021-05-29T10:07:43.99571Z"
    },
    "papermill": {
     "duration": 0.092752,
     "end_time": "2021-05-29T11:47:41.797704",
     "exception": false,
     "start_time": "2021-05-29T11:47:41.704952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cutting-oakland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:41.971660Z",
     "iopub.status.busy": "2021-05-29T11:47:41.970817Z",
     "iopub.status.idle": "2021-05-29T11:47:41.973587Z",
     "shell.execute_reply": "2021-05-29T11:47:41.973191Z",
     "shell.execute_reply.started": "2021-05-29T10:07:44.00715Z"
    },
    "papermill": {
     "duration": 0.092389,
     "end_time": "2021-05-29T11:47:41.973695",
     "exception": false,
     "start_time": "2021-05-29T11:47:41.881306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(nn.Module):\n",
    "    def __init__(self,df,tokenizer,max_len=128):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],\n",
    "                                return_tensors='pt',\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length',\n",
    "                                truncation=True)\n",
    "        \n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "anticipated-glenn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:42.149558Z",
     "iopub.status.busy": "2021-05-29T11:47:42.148759Z",
     "iopub.status.idle": "2021-05-29T11:47:42.151357Z",
     "shell.execute_reply": "2021-05-29T11:47:42.150966Z",
     "shell.execute_reply.started": "2021-05-29T10:07:44.019011Z"
    },
    "papermill": {
     "duration": 0.094839,
     "end_time": "2021-05-29T11:47:42.151474",
     "exception": false,
     "start_time": "2021-05-29T11:47:42.056635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    MODEL_PATH = path\n",
    "    model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    ds = CLRPDataset(df,tokenizer,config['max_len'])\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs[0][:,0].detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "concrete-carry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:47:42.330147Z",
     "iopub.status.busy": "2021-05-29T11:47:42.329416Z",
     "iopub.status.idle": "2021-05-29T11:48:10.878287Z",
     "shell.execute_reply": "2021-05-29T11:48:10.878880Z",
     "shell.execute_reply.started": "2021-05-29T10:07:44.03153Z"
    },
    "papermill": {
     "duration": 28.640901,
     "end_time": "2021-05-29T11:48:10.879088",
     "exception": false,
     "start_time": "2021-05-29T11:47:42.238187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "23it [00:22,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/modelf1 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings =  get_embeddings(train_data,'../input/modelf1')\n",
    "test_embeddings = get_embeddings(test_data,'../input/modelf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "encouraging-flavor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:48:11.076522Z",
     "iopub.status.busy": "2021-05-29T11:48:11.075723Z",
     "iopub.status.idle": "2021-05-29T11:48:11.124628Z",
     "shell.execute_reply": "2021-05-29T11:48:11.124183Z",
     "shell.execute_reply.started": "2021-05-29T10:08:12.783935Z"
    },
    "papermill": {
     "duration": 0.152359,
     "end_time": "2021-05-29T11:48:11.124750",
     "exception": false,
     "start_time": "2021-05-29T11:48:10.972391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#giotto-tda , topological features extraction\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Amplitude, NumberOfPoints, PersistenceEntropy\n",
    "\n",
    "def extract_features(X, time_delay=1, dimension=1, stride=10, h_dim=(0,1), n_jobs=-1):\n",
    "    \n",
    "    samples = X\n",
    "    \n",
    "    TE = TakensEmbedding(time_delay=time_delay, dimension=dimension, stride=stride)   \n",
    "    te = TE.fit_transform(samples)\n",
    "        \n",
    "    VR = VietorisRipsPersistence(homology_dimensions=h_dim, n_jobs=n_jobs)\n",
    "    X_vr = VR.fit_transform(te)\n",
    "    \n",
    "    X_features = []\n",
    "    \n",
    "    #amplitude\n",
    "    metrics =  ['bottleneck','wasserstein', 'betti', 'landscape', 'silhouette', 'heat']\n",
    "    for metric in metrics:\n",
    "        Ampl = Amplitude(metric=metric, n_jobs=n_jobs)\n",
    "        X_a = Ampl.fit_transform(X_vr)\n",
    "        X_features.append(X_a[:,0])\n",
    "        #X_features.append(X_a[:,1])\n",
    "        \n",
    "    #entropy\n",
    "    PE = PersistenceEntropy(normalize=True, nan_fill_value=-1, n_jobs=n_jobs)\n",
    "    X_pe = PE.fit_transform(X_vr)\n",
    "    \n",
    "    X_features.append(X_pe[:,0])\n",
    "    #X_features.append(X_pe[:,1])\n",
    "\n",
    "    PE = PersistenceEntropy(normalize=False, nan_fill_value=-1, n_jobs=n_jobs)\n",
    "    X_pe = PE.fit_transform(X_vr)\n",
    "\n",
    "    X_features.append(X_pe[:,0])\n",
    "    #X_features.append(X_pe[:,1])\n",
    "\n",
    "    #number of points\n",
    "    #NOP = NumberOfPoints(n_jobs=n_jobs)\n",
    "    #X_nop = NOP.fit_transform(X_vr)\n",
    "\n",
    "    #X_features.append(X_nop[:,0])\n",
    "    #X_features.append(X_nop[:,1])\n",
    "    \n",
    "    X_features = np.array(X_features).T\n",
    "      \n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollywood-cosmetic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:48:11.314695Z",
     "iopub.status.busy": "2021-05-29T11:48:11.313773Z",
     "iopub.status.idle": "2021-05-29T11:50:47.018420Z",
     "shell.execute_reply": "2021-05-29T11:50:47.017903Z",
     "shell.execute_reply.started": "2021-05-29T10:08:12.84321Z"
    },
    "papermill": {
     "duration": 155.800976,
     "end_time": "2021-05-29T11:50:47.018562",
     "exception": false,
     "start_time": "2021-05-29T11:48:11.217586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tda_features_train = extract_features(train_embeddings, stride = 2)\n",
    "tda_features_test = extract_features(test_embeddings, stride = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "structural-closer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:50:47.209476Z",
     "iopub.status.busy": "2021-05-29T11:50:47.208690Z",
     "iopub.status.idle": "2021-05-29T11:50:47.215621Z",
     "shell.execute_reply": "2021-05-29T11:50:47.215998Z",
     "shell.execute_reply.started": "2021-05-29T10:10:47.751747Z"
    },
    "papermill": {
     "duration": 0.104293,
     "end_time": "2021-05-29T11:50:47.216132",
     "exception": false,
     "start_time": "2021-05-29T11:50:47.111839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard scaler on tda features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tda_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "scheduled-video",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:50:47.405540Z",
     "iopub.status.busy": "2021-05-29T11:50:47.404814Z",
     "iopub.status.idle": "2021-05-29T11:50:47.407289Z",
     "shell.execute_reply": "2021-05-29T11:50:47.407696Z",
     "shell.execute_reply.started": "2021-05-29T10:10:47.764086Z"
    },
    "papermill": {
     "duration": 0.099528,
     "end_time": "2021-05-29T11:50:47.407830",
     "exception": false,
     "start_time": "2021-05-29T11:50:47.308302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tda_train_norm = scaler.transform(tda_features_train)\n",
    "tda_test_norm = scaler.transform(tda_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "failing-deadline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:50:47.597098Z",
     "iopub.status.busy": "2021-05-29T11:50:47.596483Z",
     "iopub.status.idle": "2021-05-29T11:50:47.600369Z",
     "shell.execute_reply": "2021-05-29T11:50:47.599972Z",
     "shell.execute_reply.started": "2021-05-29T10:10:47.772393Z"
    },
    "papermill": {
     "duration": 0.100022,
     "end_time": "2021-05-29T11:50:47.600487",
     "exception": false,
     "start_time": "2021-05-29T11:50:47.500465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stacking roberta features (embedding) and tda_features\n",
    "#train_embeddings_final = np.hstack((train_embeddings, tda_features_train))\n",
    "#test_embeddings_final = np.hstack((test_embeddings, tda_features_test))\n",
    "\n",
    "#train_embeddings_final = np.hstack((train_embeddings, tda_train_norm))\n",
    "#test_embeddings_final = np.hstack((test_embeddings, tda_test_norm))\n",
    "\n",
    "train_embeddings_final = train_embeddings\n",
    "test_embeddings_final = test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "legislative-fancy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:50:47.792590Z",
     "iopub.status.busy": "2021-05-29T11:50:47.792079Z",
     "iopub.status.idle": "2021-05-29T11:51:55.871539Z",
     "shell.execute_reply": "2021-05-29T11:51:55.871096Z",
     "shell.execute_reply.started": "2021-05-29T10:10:47.781578Z"
    },
    "papermill": {
     "duration": 68.179623,
     "end_time": "2021-05-29T11:51:55.871662",
     "exception": false,
     "start_time": "2021-05-29T11:50:47.692039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3357]\ttraining's rmse: 0.248122\tvalid_1's rmse: 0.359864\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2124]\ttraining's rmse: 0.272074\tvalid_1's rmse: 0.356901\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4020]\ttraining's rmse: 0.237888\tvalid_1's rmse: 0.353208\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1679]\ttraining's rmse: 0.276484\tvalid_1's rmse: 0.386539\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[929]\ttraining's rmse: 0.304554\tvalid_1's rmse: 0.363999\n"
     ]
    }
   ],
   "source": [
    "# lgbm on roberta features\n",
    "lgbm_preds = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha':6.147694913504962,\n",
    " 'reg_lambda':  0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "lgb_models = list()\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train_embeddings_final[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(train_embeddings_final[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds += lgb_model.predict(test_embeddings_final)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excessive-talent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:51:56.067825Z",
     "iopub.status.busy": "2021-05-29T11:51:56.067104Z",
     "iopub.status.idle": "2021-05-29T11:52:02.925142Z",
     "shell.execute_reply": "2021-05-29T11:52:02.925554Z",
     "shell.execute_reply.started": "2021-05-29T10:11:55.292357Z"
    },
    "papermill": {
     "duration": 6.960188,
     "end_time": "2021-05-29T11:52:02.925713",
     "exception": false,
     "start_time": "2021-05-29T11:51:55.965525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4897]\ttraining's rmse: 0.410148\tvalid_1's rmse: 0.445451\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4294]\ttraining's rmse: 0.4064\tvalid_1's rmse: 0.453956\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.415631\tvalid_1's rmse: 0.41028\n",
      "Early stopping, best iteration is:\n",
      "[14382]\ttraining's rmse: 0.415036\tvalid_1's rmse: 0.41006\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2377]\ttraining's rmse: 0.414467\tvalid_1's rmse: 0.435023\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5173]\ttraining's rmse: 0.413439\tvalid_1's rmse: 0.416422\n"
     ]
    }
   ],
   "source": [
    "# lgbm on topological features\n",
    "lgbm_preds_tda = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "lgb_models = list()\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda += lgb_model.predict(tda_test_norm)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "auburn-former",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:52:03.123933Z",
     "iopub.status.busy": "2021-05-29T11:52:03.123404Z",
     "iopub.status.idle": "2021-05-29T11:52:03.127212Z",
     "shell.execute_reply": "2021-05-29T11:52:03.126790Z",
     "shell.execute_reply.started": "2021-05-29T10:12:02.414724Z"
    },
    "papermill": {
     "duration": 0.104025,
     "end_time": "2021-05-29T11:52:03.127323",
     "exception": false,
     "start_time": "2021-05-29T11:52:03.023298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Yum Yum Ensembling\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "confident-somalia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:52:03.333262Z",
     "iopub.status.busy": "2021-05-29T11:52:03.332658Z",
     "iopub.status.idle": "2021-05-29T11:53:43.827444Z",
     "shell.execute_reply": "2021-05-29T11:53:43.827858Z",
     "shell.execute_reply.started": "2021-05-29T10:12:02.421665Z"
    },
    "papermill": {
     "duration": 100.603562,
     "end_time": "2021-05-29T11:53:43.828057",
     "exception": false,
     "start_time": "2021-05-29T11:52:03.224495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Notebook forkato da Yum Yum Yum \n",
    "class Dataset:\n",
    "    def __init__(self, excerpt, tokenizer, max_len):\n",
    "        self.excerpt = excerpt\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.excerpt[item])\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            max_length=self.max_len, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    \n",
    "    \n",
    "def generate_predictions(model_path, max_len):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    \n",
    "    df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n",
    "    \n",
    "    dataset = Dataset(excerpt=df.excerpt.values, tokenizer=tokenizer, max_len=max_len)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=32, num_workers=4, pin_memory=True, shuffle=False\n",
    "    )\n",
    "\n",
    "    final_output = []\n",
    "\n",
    "    for b_idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(\"cuda\")\n",
    "            output = model(**data)\n",
    "            output = output.logits.detach().cpu().numpy().ravel().tolist()\n",
    "            final_output.extend(output)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    return np.array(final_output)\n",
    "\n",
    "\n",
    "preds1 = generate_predictions(\"../input/a81653/\", max_len=256)\n",
    "preds2 = generate_predictions(\"../input/a81656/\", max_len=256)\n",
    "preds3 = generate_predictions(\"../input/a81657/\", max_len=256)\n",
    "preds4 = generate_predictions(\"../input/a81660/\", max_len=256)\n",
    "preds5 = generate_predictions(\"../input/a81675/\", max_len=192)\n",
    "preds6 = generate_predictions(\"../input/a87832/\", max_len=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-addition",
   "metadata": {
    "papermill": {
     "duration": 0.096424,
     "end_time": "2021-05-29T11:53:44.022612",
     "exception": false,
     "start_time": "2021-05-29T11:53:43.926188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RoBERTa Large - Fine tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "gentle-mistake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:44.237749Z",
     "iopub.status.busy": "2021-05-29T11:53:44.236993Z",
     "iopub.status.idle": "2021-05-29T11:53:44.269699Z",
     "shell.execute_reply": "2021-05-29T11:53:44.269238Z",
     "shell.execute_reply.started": "2021-05-29T11:38:16.887287Z"
    },
    "papermill": {
     "duration": 0.149911,
     "end_time": "2021-05-29T11:53:44.269809",
     "exception": false,
     "start_time": "2021-05-29T11:53:44.119898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "train = train[train[\"target\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tough-board",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:44.469583Z",
     "iopub.status.busy": "2021-05-29T11:53:44.468937Z",
     "iopub.status.idle": "2021-05-29T11:53:44.471773Z",
     "shell.execute_reply": "2021-05-29T11:53:44.472157Z",
     "shell.execute_reply.started": "2021-05-29T11:38:17.381225Z"
    },
    "papermill": {
     "duration": 0.105936,
     "end_time": "2021-05-29T11:53:44.472287",
     "exception": false,
     "start_time": "2021-05-29T11:53:44.366351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "major-building",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:44.674328Z",
     "iopub.status.busy": "2021-05-29T11:53:44.673626Z",
     "iopub.status.idle": "2021-05-29T11:53:44.677307Z",
     "shell.execute_reply": "2021-05-29T11:53:44.676892Z",
     "shell.execute_reply.started": "2021-05-29T11:38:17.464787Z"
    },
    "papermill": {
     "duration": 0.108659,
     "end_time": "2021-05-29T11:53:44.677427",
     "exception": false,
     "start_time": "2021-05-29T11:53:44.568768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "romantic-authentication",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:44.887414Z",
     "iopub.status.busy": "2021-05-29T11:53:44.886705Z",
     "iopub.status.idle": "2021-05-29T11:53:44.890292Z",
     "shell.execute_reply": "2021-05-29T11:53:44.889845Z",
     "shell.execute_reply.started": "2021-05-29T11:38:17.547565Z"
    },
    "papermill": {
     "duration": 0.105878,
     "end_time": "2021-05-29T11:53:44.890397",
     "exception": false,
     "start_time": "2021-05-29T11:53:44.784519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "medieval-beads",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:45.093241Z",
     "iopub.status.busy": "2021-05-29T11:53:45.091975Z",
     "iopub.status.idle": "2021-05-29T11:53:45.094338Z",
     "shell.execute_reply": "2021-05-29T11:53:45.094723Z",
     "shell.execute_reply.started": "2021-05-29T11:38:17.647699Z"
    },
    "papermill": {
     "duration": 0.108185,
     "end_time": "2021-05-29T11:53:45.094846",
     "exception": false,
     "start_time": "2021-05-29T11:53:44.986661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "constitutional-standing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:45.302483Z",
     "iopub.status.busy": "2021-05-29T11:53:45.301810Z",
     "iopub.status.idle": "2021-05-29T11:53:45.304745Z",
     "shell.execute_reply": "2021-05-29T11:53:45.305118Z",
     "shell.execute_reply.started": "2021-05-29T11:38:17.750971Z"
    },
    "papermill": {
     "duration": 0.113276,
     "end_time": "2021-05-29T11:53:45.305246",
     "exception": false,
     "start_time": "2021-05-29T11:53:45.191970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "annoying-victorian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:45.504224Z",
     "iopub.status.busy": "2021-05-29T11:53:45.503542Z",
     "iopub.status.idle": "2021-05-29T11:53:45.507136Z",
     "shell.execute_reply": "2021-05-29T11:53:45.506723Z",
     "shell.execute_reply.started": "2021-05-29T11:38:18.043365Z"
    },
    "papermill": {
     "duration": 0.105628,
     "end_time": "2021-05-29T11:53:45.507241",
     "exception": false,
     "start_time": "2021-05-29T11:53:45.401613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(model_name='roberta-large', num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "spanish-vessel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:45.709360Z",
     "iopub.status.busy": "2021-05-29T11:53:45.708808Z",
     "iopub.status.idle": "2021-05-29T11:53:45.712289Z",
     "shell.execute_reply": "2021-05-29T11:53:45.712649Z",
     "shell.execute_reply.started": "2021-05-29T11:38:18.233042Z"
    },
    "papermill": {
     "duration": 0.108137,
     "end_time": "2021-05-29T11:53:45.712774",
     "exception": false,
     "start_time": "2021-05-29T11:53:45.604637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "utility-pepper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:45.914217Z",
     "iopub.status.busy": "2021-05-29T11:53:45.912750Z",
     "iopub.status.idle": "2021-05-29T11:53:45.915041Z",
     "shell.execute_reply": "2021-05-29T11:53:45.915463Z",
     "shell.execute_reply.started": "2021-05-29T11:38:18.570348Z"
    },
    "papermill": {
     "duration": 0.106417,
     "end_time": "2021-05-29T11:53:45.915587",
     "exception": false,
     "start_time": "2021-05-29T11:53:45.809170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "biblical-occurrence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:46.115960Z",
     "iopub.status.busy": "2021-05-29T11:53:46.115429Z",
     "iopub.status.idle": "2021-05-29T11:53:46.119145Z",
     "shell.execute_reply": "2021-05-29T11:53:46.118724Z",
     "shell.execute_reply.started": "2021-05-29T11:38:18.970636Z"
    },
    "papermill": {
     "duration": 0.106294,
     "end_time": "2021-05-29T11:53:46.119255",
     "exception": false,
     "start_time": "2021-05-29T11:53:46.012961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "delayed-reducing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:53:46.319602Z",
     "iopub.status.busy": "2021-05-29T11:53:46.319066Z",
     "iopub.status.idle": "2021-05-29T11:56:54.369592Z",
     "shell.execute_reply": "2021-05-29T11:56:54.368190Z"
    },
    "papermill": {
     "duration": 188.153771,
     "end_time": "2021-05-29T11:56:54.369724",
     "exception": false,
     "start_time": "2021-05-29T11:53:46.215953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:50<03:20, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:36<02:24, 48.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:06<01:19, 39.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:37<00:36, 36.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:07<00:00, 37.59s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta/roberta-base/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold}'] = run(fold, '../input/robertalarge/', '../input/robertalargeitptfit/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "stunning-quilt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:56:54.621298Z",
     "iopub.status.busy": "2021-05-29T11:56:54.620324Z",
     "iopub.status.idle": "2021-05-29T11:56:54.623275Z",
     "shell.execute_reply": "2021-05-29T11:56:54.622853Z",
     "shell.execute_reply.started": "2021-05-29T10:15:31.314799Z"
    },
    "papermill": {
     "duration": 0.151724,
     "end_time": "2021-05-29T11:56:54.623389",
     "exception": false,
     "start_time": "2021-05-29T11:56:54.471665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_preds1 = pred_df1.mean(axis=1).values.tolist()\n",
    "last_preds2 = pred_df2.mean(axis=1).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "handmade-keyboard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:56:54.832016Z",
     "iopub.status.busy": "2021-05-29T11:56:54.831452Z",
     "iopub.status.idle": "2021-05-29T11:56:54.834838Z",
     "shell.execute_reply": "2021-05-29T11:56:54.835223Z",
     "shell.execute_reply.started": "2021-05-29T10:15:31.335884Z"
    },
    "papermill": {
     "duration": 0.109797,
     "end_time": "2021-05-29T11:56:54.835359",
     "exception": false,
     "start_time": "2021-05-29T11:56:54.725562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = (svm_preds1[:,0] + svm_preds2[:,0] + svm_preds3[:,0] + svm_preds4[:,0] + svm_preds5[:,0] \n",
    "         + lgbm_preds + lgbm_preds_tda \n",
    "         + preds1 + preds2 + preds3 + preds4 + preds5 + preds6 \n",
    "         + last_preds1 + last_preds2)/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "soviet-interpretation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T11:56:55.047474Z",
     "iopub.status.busy": "2021-05-29T11:56:55.046923Z",
     "iopub.status.idle": "2021-05-29T11:56:55.102983Z",
     "shell.execute_reply": "2021-05-29T11:56:55.102509Z",
     "shell.execute_reply.started": "2021-05-29T10:15:47.967799Z"
    },
    "papermill": {
     "duration": 0.166464,
     "end_time": "2021-05-29T11:56:55.103108",
     "exception": false,
     "start_time": "2021-05-29T11:56:54.936644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\n",
    "submission.target = preds\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1013.962882,
   "end_time": "2021-05-29T11:56:58.644868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-29T11:40:04.681986",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
