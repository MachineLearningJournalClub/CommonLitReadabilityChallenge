{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "traditional-notification",
   "metadata": {
    "papermill": {
     "duration": 0.018291,
     "end_time": "2021-06-13T15:06:08.066841",
     "exception": false,
     "start_time": "2021-06-13T15:06:08.048550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook uses below given notebooks to make predictions.\n",
    "\n",
    "1. LB 0.468 https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3\n",
    "2. LB 0.474 https://www.kaggle.com/maunish/clrp-roberta-svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "official-monitor",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:08.114072Z",
     "iopub.status.busy": "2021-06-13T15:06:08.113389Z",
     "iopub.status.idle": "2021-06-13T15:06:14.160275Z",
     "shell.execute_reply": "2021-06-13T15:06:14.159697Z",
     "shell.execute_reply.started": "2021-06-13T14:56:12.780494Z"
    },
    "papermill": {
     "duration": 6.076395,
     "end_time": "2021-06-13T15:06:14.160435",
     "exception": false,
     "start_time": "2021-06-13T15:06:08.084040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organic-antarctica",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.201864Z",
     "iopub.status.busy": "2021-06-13T15:06:14.201365Z",
     "iopub.status.idle": "2021-06-13T15:06:14.308172Z",
     "shell.execute_reply": "2021-06-13T15:06:14.308657Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.784125Z"
    },
    "papermill": {
     "duration": 0.131244,
     "end_time": "2021-06-13T15:06:14.308801",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.177557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "\n",
    "num_bins = 10 #int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
    "\n",
    "target = train_data['target'].to_numpy()\n",
    "bins = train_data.bins.to_numpy()\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daily-advancement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.349003Z",
     "iopub.status.busy": "2021-06-13T15:06:14.348501Z",
     "iopub.status.idle": "2021-06-13T15:06:14.355021Z",
     "shell.execute_reply": "2021-06-13T15:06:14.354594Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.886614Z"
    },
    "papermill": {
     "duration": 0.028644,
     "end_time": "2021-06-13T15:06:14.355137",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.326493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'nfolds':5,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "altered-administrator",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.395247Z",
     "iopub.status.busy": "2021-06-13T15:06:14.394383Z",
     "iopub.status.idle": "2021-06-13T15:06:14.396949Z",
     "shell.execute_reply": "2021-06-13T15:06:14.396436Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.901692Z"
    },
    "papermill": {
     "duration": 0.024389,
     "end_time": "2021-06-13T15:06:14.397048",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.372659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alone-immigration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.436987Z",
     "iopub.status.busy": "2021-06-13T15:06:14.436245Z",
     "iopub.status.idle": "2021-06-13T15:06:14.438440Z",
     "shell.execute_reply": "2021-06-13T15:06:14.438847Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.913523Z"
    },
    "papermill": {
     "duration": 0.025092,
     "end_time": "2021-06-13T15:06:14.438960",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.413868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "\n",
    "        score = self.V(att)\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surrounded-bride",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.478019Z",
     "iopub.status.busy": "2021-06-13T15:06:14.477332Z",
     "iopub.status.idle": "2021-06-13T15:06:14.480010Z",
     "shell.execute_reply": "2021-06-13T15:06:14.479624Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.928470Z"
    },
    "papermill": {
     "duration": 0.024275,
     "end_time": "2021-06-13T15:06:14.480109",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.455834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n",
    "        self.head = AttentionHead(768,768,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.head.out_features,1)\n",
    "\n",
    "    def forward(self,**xb):\n",
    "        x = self.roberta(**xb)[0]\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fossil-provincial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.522214Z",
     "iopub.status.busy": "2021-06-13T15:06:14.521376Z",
     "iopub.status.idle": "2021-06-13T15:06:14.524043Z",
     "shell.execute_reply": "2021-06-13T15:06:14.523655Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.941598Z"
    },
    "papermill": {
     "duration": 0.027137,
     "end_time": "2021-06-13T15:06:14.524160",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.497023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n",
    "    \n",
    "    ds = CLRPDataset(df,tokenizer)\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moving-ending",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:06:14.609121Z",
     "iopub.status.busy": "2021-06-13T15:06:14.608525Z",
     "iopub.status.idle": "2021-06-13T15:09:13.090447Z",
     "shell.execute_reply": "2021-06-13T15:09:13.091001Z",
     "shell.execute_reply.started": "2021-06-13T14:56:20.961423Z"
    },
    "papermill": {
     "duration": 178.549465,
     "end_time": "2021-06-13T15:09:13.091206",
     "exception": false,
     "start_time": "2021-06-13T15:06:14.541741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:22,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(train_data,'../input/d/maunish/clr-roberta/model0/model0.bin')\n",
    "test_embeddings1 = get_embeddings(test_data,'../input/d/maunish/clr-roberta/model0/model0.bin')\n",
    "\n",
    "train_embeddings2 =  get_embeddings(train_data,'../input/d/maunish/clr-roberta/model1/model1.bin')\n",
    "test_embeddings2 = get_embeddings(test_data,'../input/d/maunish/clr-roberta/model1/model1.bin')\n",
    "\n",
    "train_embeddings3 =  get_embeddings(train_data,'../input/d/maunish/clr-roberta/model2/model2.bin')\n",
    "test_embeddings3 = get_embeddings(test_data,'../input/d/maunish/clr-roberta/model2/model2.bin')\n",
    "\n",
    "train_embeddings4 =  get_embeddings(train_data,'../input/d/maunish/clr-roberta/model3/model3.bin')\n",
    "test_embeddings4 = get_embeddings(test_data,'../input/d/maunish/clr-roberta/model3/model3.bin')\n",
    "\n",
    "train_embeddings5 =  get_embeddings(train_data,'../input/d/maunish/clr-roberta/model4/model4.bin')\n",
    "test_embeddings5 = get_embeddings(test_data,'../input/d/maunish/clr-roberta/model4/model4.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-amplifier",
   "metadata": {
    "papermill": {
     "duration": 0.054428,
     "end_time": "2021-06-13T15:09:13.202519",
     "exception": false,
     "start_time": "2021-06-13T15:09:13.148091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opposed-words",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:13.320559Z",
     "iopub.status.busy": "2021-06-13T15:09:13.319933Z",
     "iopub.status.idle": "2021-06-13T15:09:13.323380Z",
     "shell.execute_reply": "2021-06-13T15:09:13.322978Z",
     "shell.execute_reply.started": "2021-06-13T14:59:30.810351Z"
    },
    "papermill": {
     "duration": 0.065936,
     "end_time": "2021-06-13T15:09:13.323483",
     "exception": false,
     "start_time": "2021-06-13T15:09:13.257547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = SVR(C=C,kernel=kernel,gamma='auto')\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "several-respondent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:13.438899Z",
     "iopub.status.busy": "2021-06-13T15:09:13.438405Z",
     "iopub.status.idle": "2021-06-13T15:09:54.333696Z",
     "shell.execute_reply": "2021-06-13T15:09:54.333184Z",
     "shell.execute_reply.started": "2021-06-13T14:59:30.823436Z"
    },
    "papermill": {
     "duration": 40.955002,
     "end_time": "2021-06-13T15:09:54.333826",
     "exception": false,
     "start_time": "2021-06-13T15:09:13.378824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.30244001668993065\n",
      "Fold 1 , rmse score: 0.3176279355882085\n",
      "Fold 2 , rmse score: 0.3121293538451774\n",
      "Fold 3 , rmse score: 0.29931410541461934\n",
      "Fold 4 , rmse score: 0.3153304830776079\n",
      "mean rmse 0.3093683789231088\n",
      "Fold 0 , rmse score: 0.29097746632351446\n",
      "Fold 1 , rmse score: 0.31702833676247216\n",
      "Fold 2 , rmse score: 0.3210759091879366\n",
      "Fold 3 , rmse score: 0.2944255630276263\n",
      "Fold 4 , rmse score: 0.3230174230834076\n",
      "mean rmse 0.3093049396769914\n",
      "Fold 0 , rmse score: 0.40084361023562914\n",
      "Fold 1 , rmse score: 0.422788809556178\n",
      "Fold 2 , rmse score: 0.43193150069327335\n",
      "Fold 3 , rmse score: 0.3979210269514241\n",
      "Fold 4 , rmse score: 0.4160254830895724\n",
      "mean rmse 0.41390208610521545\n",
      "Fold 0 , rmse score: 0.30960010620357015\n",
      "Fold 1 , rmse score: 0.310944155947877\n",
      "Fold 2 , rmse score: 0.332661561738457\n",
      "Fold 3 , rmse score: 0.32617667433403497\n",
      "Fold 4 , rmse score: 0.32990097970746346\n",
      "mean rmse 0.3218566955862805\n",
      "Fold 0 , rmse score: 0.40607340974010303\n",
      "Fold 1 , rmse score: 0.4329604794370854\n",
      "Fold 2 , rmse score: 0.43956708909686826\n",
      "Fold 3 , rmse score: 0.42311172023872423\n",
      "Fold 4 , rmse score: 0.4276445006164484\n",
      "mean rmse 0.42587143982584585\n"
     ]
    }
   ],
   "source": [
    "svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n",
    "svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n",
    "svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n",
    "svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n",
    "svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informative-blade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:54.460717Z",
     "iopub.status.busy": "2021-06-13T15:09:54.460191Z",
     "iopub.status.idle": "2021-06-13T15:09:54.464037Z",
     "shell.execute_reply": "2021-06-13T15:09:54.463647Z",
     "shell.execute_reply.started": "2021-06-13T15:00:17.378794Z"
    },
    "papermill": {
     "duration": 0.068291,
     "end_time": "2021-06-13T15:09:54.464143",
     "exception": false,
     "start_time": "2021-06-13T15:09:54.395852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-chest",
   "metadata": {
    "papermill": {
     "duration": 0.061238,
     "end_time": "2021-06-13T15:09:54.586418",
     "exception": false,
     "start_time": "2021-06-13T15:09:54.525180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The second notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nonprofit-cancellation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:54.726316Z",
     "iopub.status.busy": "2021-06-13T15:09:54.725010Z",
     "iopub.status.idle": "2021-06-13T15:09:54.727393Z",
     "shell.execute_reply": "2021-06-13T15:09:54.727810Z",
     "shell.execute_reply.started": "2021-06-13T15:00:17.387905Z"
    },
    "papermill": {
     "duration": 0.08035,
     "end_time": "2021-06-13T15:09:54.727947",
     "exception": false,
     "start_time": "2021-06-13T15:09:54.647597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "visible-solomon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:54.857151Z",
     "iopub.status.busy": "2021-06-13T15:09:54.856622Z",
     "iopub.status.idle": "2021-06-13T15:09:59.212823Z",
     "shell.execute_reply": "2021-06-13T15:09:59.212340Z",
     "shell.execute_reply.started": "2021-06-13T15:00:17.413910Z"
    },
    "papermill": {
     "duration": 4.423455,
     "end_time": "2021-06-13T15:09:59.212959",
     "exception": false,
     "start_time": "2021-06-13T15:09:54.789504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moderate-candy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:59.374438Z",
     "iopub.status.busy": "2021-06-13T15:09:59.373096Z",
     "iopub.status.idle": "2021-06-13T15:09:59.375449Z",
     "shell.execute_reply": "2021-06-13T15:09:59.375936Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.456508Z"
    },
    "papermill": {
     "duration": 0.07031,
     "end_time": "2021-06-13T15:09:59.376058",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.305748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cross-silly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:59.508031Z",
     "iopub.status.busy": "2021-06-13T15:09:59.507384Z",
     "iopub.status.idle": "2021-06-13T15:09:59.510085Z",
     "shell.execute_reply": "2021-06-13T15:09:59.509697Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.468807Z"
    },
    "papermill": {
     "duration": 0.072672,
     "end_time": "2021-06-13T15:09:59.510188",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.437516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exciting-start",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:59.645235Z",
     "iopub.status.busy": "2021-06-13T15:09:59.644582Z",
     "iopub.status.idle": "2021-06-13T15:09:59.647277Z",
     "shell.execute_reply": "2021-06-13T15:09:59.646882Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.486454Z"
    },
    "papermill": {
     "duration": 0.075902,
     "end_time": "2021-06-13T15:09:59.647377",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.571475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "northern-blind",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:59.776176Z",
     "iopub.status.busy": "2021-06-13T15:09:59.775461Z",
     "iopub.status.idle": "2021-06-13T15:09:59.777675Z",
     "shell.execute_reply": "2021-06-13T15:09:59.778096Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.508761Z"
    },
    "papermill": {
     "duration": 0.069114,
     "end_time": "2021-06-13T15:09:59.778204",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.709090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "female-research",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:09:59.907443Z",
     "iopub.status.busy": "2021-06-13T15:09:59.906784Z",
     "iopub.status.idle": "2021-06-13T15:09:59.909050Z",
     "shell.execute_reply": "2021-06-13T15:09:59.909497Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.524593Z"
    },
    "papermill": {
     "duration": 0.070625,
     "end_time": "2021-06-13T15:09:59.909616",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.838991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adopted-consistency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:10:00.038251Z",
     "iopub.status.busy": "2021-06-13T15:10:00.037489Z",
     "iopub.status.idle": "2021-06-13T15:10:00.040187Z",
     "shell.execute_reply": "2021-06-13T15:10:00.039752Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.542353Z"
    },
    "papermill": {
     "duration": 0.070029,
     "end_time": "2021-06-13T15:10:00.040300",
     "exception": false,
     "start_time": "2021-06-13T15:09:59.970271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "following-damage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:10:00.168233Z",
     "iopub.status.busy": "2021-06-13T15:10:00.167537Z",
     "iopub.status.idle": "2021-06-13T15:10:00.170291Z",
     "shell.execute_reply": "2021-06-13T15:10:00.169887Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.559624Z"
    },
    "papermill": {
     "duration": 0.068991,
     "end_time": "2021-06-13T15:10:00.170395",
     "exception": false,
     "start_time": "2021-06-13T15:10:00.101404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "every-presence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:10:00.300341Z",
     "iopub.status.busy": "2021-06-13T15:10:00.299461Z",
     "iopub.status.idle": "2021-06-13T15:14:34.711274Z",
     "shell.execute_reply": "2021-06-13T15:14:34.709618Z",
     "shell.execute_reply.started": "2021-06-13T15:00:23.577092Z"
    },
    "papermill": {
     "duration": 274.479788,
     "end_time": "2021-06-13T15:14:34.711441",
     "exception": false,
     "start_time": "2021-06-13T15:10:00.231653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:07<04:28, 67.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:58<02:52, 57.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:50<01:50, 55.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:42<00:54, 54.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:34<00:00, 54.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 15.8 s, total: 1min 47s\n",
      "Wall time: 4min 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "\n",
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cordless-immunology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-13T15:14:34.853738Z",
     "iopub.status.busy": "2021-06-13T15:14:34.853089Z",
     "iopub.status.idle": "2021-06-13T15:14:34.974195Z",
     "shell.execute_reply": "2021-06-13T15:14:34.973785Z",
     "shell.execute_reply.started": "2021-06-13T15:05:12.071514Z"
    },
    "papermill": {
     "duration": 0.194797,
     "end_time": "2021-06-13T15:14:34.974338",
     "exception": false,
     "start_time": "2021-06-13T15:14:34.779541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample['target'] = (pred_df2.mean(axis=1)*0.35) + (pred_df1.mean(axis=1)*0.20) + (pred_df3.mean(axis=1) * 0.15) + (svm_preds * 0.30)\n",
    "sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 515.761057,
   "end_time": "2021-06-13T15:14:37.434626",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-13T15:06:01.673569",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
