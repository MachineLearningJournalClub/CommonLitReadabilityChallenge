{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"code","source":"!python -m pip install \"../input/roberta/sentence-transformers/\"\n!pip install Pyphen --no-index --find-links=file:///kaggle/input/roberta/Pyphen-0.9.5-py2.py3-none-any.whl\n!pip install repoze.lru --no-index --find-links=file:///kaggle/input/roberta/repoze.lru-0.7-py3-none-any.whl\n!pip install textstat --no-index --find-links=file:///kaggle/input/roberta/textstat-0.7.0-py3-none-any.whl","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/roberta/sentence-transformers\nRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (4.5.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (4.59.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (1.7.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (1.19.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (0.24.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (1.5.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==1.1.0) (0.1.95)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers==1.1.0) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers==1.1.0) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers==1.1.0) (0.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (2021.3.17)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (3.4.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (0.0.45)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (20.9)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (2.25.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (0.10.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (3.0.12)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (3.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==1.1.0) (1.15.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (2020.12.5)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (7.1.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers==1.1.0) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==1.1.0) (2.1.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-py3-none-any.whl size=126496 sha256=e092021b9ff273f97d52ccfc3cb8fef7d0e387af33e3b7c8b483c5931ccbca8d\n  Stored in directory: /root/.cache/pip/wheels/86/8c/ce/e33b1f3855d444c071cfabd0fc7880faef2b93e5dea2208f90\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-1.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport numpy as np\nimport pandas as pd\n#from sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport textstat","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"ind = np.where(train_df.standard_error == train_df.standard_error.min())[0]\ntrain_df.loc[ind]","metadata":{"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"            id url_legal license  \\\n106  436ce79fe       NaN     NaN   \n\n                                               excerpt  target  standard_error  \n106  The sun was shining in a cloudless sky, and no...     0.0             0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url_legal</th>\n      <th>license</th>\n      <th>excerpt</th>\n      <th>target</th>\n      <th>standard_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>106</th>\n      <td>436ce79fe</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The sun was shining in a cloudless sky, and no...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This row has a target which looks like an integer, and a 0 standard error.  \nWe'll remove it for now, as the standard error is largely out of distribution, which could affect dimensionality reduction","metadata":{}},{"cell_type":"code","source":"train_df.drop(ind, inplace = True)\ntrain_df.reset_index(inplace = True,drop = True)","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Obtaining Sentence Representations","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, models","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_path = \"../input/roberta/roberta-base/roberta-base\"\nword_embedding_model = models.Transformer(model_path, max_seq_length=256)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\nroberta = SentenceTransformer(modules=[word_embedding_model, pooling_model])","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# bert = SentenceTransformer('bert-base-uncased')\n# roberta = SentenceTransformer('../input/roberta/roberta-base/roberta-base')\nvects = roberta.encode(train_df.excerpt)","metadata":{"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35db3851573344ecb4a579806523cd55"}},"metadata":{}}]},{"cell_type":"code","source":"#mpnet = SentenceTransformer(\"stsb-mpnet-base-v2\")\n#vects = mpnet.encode(train_df.excerpt)","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Probably isn't neccesary to scale these vectors\n#scaler = StandardScaler()\n#vects = scaler.fit_transform(vects)","metadata":{"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"##  Feature Engineering\nI used the same textstat augmentations from this excellent EDA notebook https://www.kaggle.com/gunesevitan/commonlit-readability-prize-eda  \nFor reference, the augmentations are defined below:\n* `character_count` - number of characters in the text\n* `digit_count` - number of digits in the text\n* `word_count` - number of words in the text\n* `unique_word_count` - number of unique words in the text\n* `mean_word_length` - average number of character that the words have in the text\n* `syllable_count` - number of syllables in the text\n* `sentence_count` - number of sentences in the text\n* `flesch_reading_ease` - [flesch reading ease score](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch_reading_ease) of the text\n* `flesch_kincaid_grade` - [flesch-kincaid grade level](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level) of the text\n* `smog_index` - [smog index](https://en.wikipedia.org/wiki/SMOG) of the text\n* `automated_readability_index` - [automated readability index](https://en.wikipedia.org/wiki/Automated_readability_index) of the text\n* `coleman_liau_index` - [colemanâ€“liau index](https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index) of the text\n* `linsear_write_formula` - [linsear write grade](hhttps://en.wikipedia.org/wiki/Linsear_Write) of the text","metadata":{}},{"cell_type":"code","source":"# label encoder on license?\n#train_df['is_licensed'] = train_df.license.notna()*1 # might be interesting to look at?\n\ntrain_df['character_count'] = train_df['excerpt'].apply(lambda x: len(str(x)))\ntrain_df['digit_count'] = train_df['excerpt'].apply(lambda x: np.sum(([int(word.isdigit()) for word in str(x).split()])))\ntrain_df['word_count'] = train_df['excerpt'].apply(textstat.lexicon_count)\ntrain_df['unique_word_count'] = train_df['excerpt'].apply(lambda x: len(set(str(x).split())))\ntrain_df['mean_word_length'] = train_df['excerpt'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\ntrain_df['syllable_count'] = train_df['excerpt'].apply(textstat.syllable_count)\ntrain_df['sentence_count'] = train_df['excerpt'].apply(textstat.sentence_count)\ntrain_df['flesch_reading_ease'] = train_df['excerpt'].apply(textstat.flesch_reading_ease)\ntrain_df['flesch_kincaid_grade'] = train_df['excerpt'].apply(textstat.flesch_kincaid_grade)\ntrain_df['smog_index'] = train_df['excerpt'].apply(textstat.smog_index)\ntrain_df['automated_readability_index'] = train_df['excerpt'].apply(textstat.automated_readability_index)\ntrain_df['coleman_liau_index'] = train_df['excerpt'].apply(textstat.coleman_liau_index)\ntrain_df['linsear_write_formula'] = train_df['excerpt'].apply(textstat.linsear_write_formula)","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error as mse","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"vect_df = pd.DataFrame(vects)\nfinal_df = pd.concat([train_df.iloc[:,6:], vect_df], axis=1)","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_train = final_df.values\ny_train = train_df[\"target\"].values\n#X_train, X_val, y_train, y_val = train_test_split(vects, train_df[\"target\"].values , test_size=0.10, random_state=42)","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.1,\n                max_depth = 2, alpha = 10, n_estimators = 1000, verbosity = 1)\n\nxg_reg.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=nan, monotone_constraints='()',\n             n_estimators=1000, n_jobs=2, num_parallel_tree=1, random_state=0,\n             reg_alpha=10, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='exact', validate_parameters=1, verbosity=1)"},"metadata":{}}]},{"cell_type":"code","source":"#preds = xg_reg.predict(X_val)","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#np.sqrt(mse(y_val, preds))","metadata":{"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.5704950188952478"},"metadata":{}}]},{"cell_type":"markdown","source":"# TEST","metadata":{}},{"cell_type":"code","source":"#vects_test = mpnet.encode(test_df.excerpt)\nvects_test = roberta.encode(test_df.excerpt)","metadata":{"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8251430ee8cb40c29447e83ffd67d508"}},"metadata":{}}]},{"cell_type":"code","source":"#test_df['is_licensed'] = test_df.license.notna()*1 # might be interesting to look at?\ntest_df['character_count'] = test_df['excerpt'].apply(lambda x: len(str(x)))\ntest_df['digit_count'] = test_df['excerpt'].apply(lambda x: np.sum(([int(word.isdigit()) for word in str(x).split()])))\ntest_df['word_count'] = test_df['excerpt'].apply(textstat.lexicon_count)\ntest_df['unique_word_count'] = test_df['excerpt'].apply(lambda x: len(set(str(x).split())))\ntest_df['mean_word_length'] = test_df['excerpt'].apply(lambda x: np.mean([len(word) for word in str(x).split()]))\ntest_df['syllable_count'] = test_df['excerpt'].apply(textstat.syllable_count)\ntest_df['sentence_count'] = test_df['excerpt'].apply(textstat.sentence_count)\ntest_df['flesch_reading_ease'] = test_df['excerpt'].apply(textstat.flesch_reading_ease)\ntest_df['flesch_kincaid_grade'] = test_df['excerpt'].apply(textstat.flesch_kincaid_grade)\ntest_df['smog_index'] = test_df['excerpt'].apply(textstat.smog_index)\ntest_df['automated_readability_index'] = test_df['excerpt'].apply(textstat.automated_readability_index)\ntest_df['coleman_liau_index'] = test_df['excerpt'].apply(textstat.coleman_liau_index)\ntest_df['linsear_write_formula'] = test_df['excerpt'].apply(textstat.linsear_write_formula)","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"vect_df_test = pd.DataFrame(vects_test)\nfinal_df_test = pd.concat([test_df.iloc[:,4:].head(), vect_df_test], axis=1)","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_test = final_df_test.values","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"y_test = xg_reg.predict(X_test)","metadata":{"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/data.py:114: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n  \"because it will generate extra copies and increase \" +\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = pd.DataFrame()\npredictions['id'] = test_df['id']\npredictions['target'] = y_test\npredictions.to_csv(\"submission.csv\", index=False)\npredictions","metadata":{"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"          id    target\n0  c0f722661 -0.670114\n1  f0953f0a5 -0.224144\n2  0df072751 -0.437058\n3  04caf4e0c -2.376087\n4  0e63f8bea -1.758820\n5  12537fe78 -0.248130\n6  965e592c0  0.196202","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c0f722661</td>\n      <td>-0.670114</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f0953f0a5</td>\n      <td>-0.224144</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0df072751</td>\n      <td>-0.437058</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04caf4e0c</td>\n      <td>-2.376087</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0e63f8bea</td>\n      <td>-1.758820</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12537fe78</td>\n      <td>-0.248130</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>965e592c0</td>\n      <td>0.196202</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}