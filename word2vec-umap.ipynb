{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commonlitreadabilityprize/test.csv\n",
      "commonlitreadabilityprize/train.csv\n",
      "commonlitreadabilityprize/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('commonlitreadabilityprize/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more common imports\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# languange processing imports\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from gensim.corpora import Dictionary\n",
    "# preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model imports\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# hyperparameter training imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# visualization imports\n",
    "import umap\n",
    "#import umap.umap_ as umap\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import io\n",
    "%matplotlib inline\n",
    "sns.set()  # defines the style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and remove non-ascii words\n",
    "# Non so se serva, ma si può modificare aggiungendo preprocessing ad-hoc\n",
    "\n",
    "our_special_word = 'qwerty'\n",
    "\n",
    "def remove_ascii_words(df):\n",
    "    \"\"\" removes non-ascii characters from the 'texts' column in df.\n",
    "    It returns the words containig non-ascii characers.\n",
    "    \"\"\"\n",
    "    non_ascii_words = []\n",
    "    for i in range(len(df)):\n",
    "        for word in df.loc[i, 'excerpt'].split(' '):\n",
    "            if any([ord(character) >= 128 for character in word]):\n",
    "                non_ascii_words.append(word)\n",
    "                df.loc[i, 'excerpt'] = df.loc[i, 'excerpt'].replace(word, our_special_word)\n",
    "    return non_ascii_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non so se serva, ma si può modificare aggiungendo preprocessing ad-hoc\n",
    "def get_good_tokens(sentence):\n",
    "    replaced_punctation = list(map(lambda token: re.sub('[^0-9A-Za-z!?]+', '', token), sentence))\n",
    "    removed_punctation = list(filter(lambda token: token, replaced_punctation))\n",
    "    return removed_punctation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we get transform the documents into sentences for the word2vecmodel\n",
    "# we made a function such that later on when we make the submission, we don't need to write duplicate code\n",
    "def w2v_preprocessing(df):\n",
    "    \"\"\" All the preprocessing steps for word2vec are done in this function.\n",
    "    All mutations are done on the dataframe itself. So this function returns\n",
    "    nothing.\n",
    "    \"\"\"\n",
    "    df['excerpt'] = df.excerpt.str.lower()\n",
    "    df['document_sentences'] = df.excerpt.str.split('.')  # split texts into individual sentences\n",
    "    df['tokenized_sentences'] = list(map(lambda sentences:\n",
    "                                         list(map(nltk.word_tokenize, sentences)),\n",
    "                                         df.document_sentences))  # tokenize sentences\n",
    "    df['tokenized_sentences'] = list(map(lambda sentences:\n",
    "                                         list(map(get_good_tokens, sentences)),\n",
    "                                         df.tokenized_sentences))  # remove unwanted characters\n",
    "    df['tokenized_sentences'] = list(map(lambda sentences:\n",
    "                                         list(filter(lambda lst: lst, sentences)),\n",
    "                                         df.tokenized_sentences))  # remove empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data =  pd.read_csv(\"commonlitreadabilityprize/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced 1327 words with characters with an ordinal >= 128 in the test data.\n"
     ]
    }
   ],
   "source": [
    "train_data.excerpt = train_data['excerpt'].apply(str)\n",
    "non_ascii_words = remove_ascii_words(train_data)\n",
    "\n",
    "print(\"Replaced {} words with characters with an ordinal >= 128 in the test data.\".format(\n",
    "    len(non_ascii_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained W2V on Google News\n",
    "W2Vmodel = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_preprocessing(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(train_data[train_data.tokenized_sentences.str.len() == 0].index, inplace= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 25633.\n",
      "Number of texts: 2834.\n"
     ]
    }
   ],
   "source": [
    "#create dictionary with all sentences\n",
    "sentences = []\n",
    "for sentence_group in train_data.tokenized_sentences:\n",
    "    sentences.extend(sentence_group)\n",
    "\n",
    "print(\"Number of sentences: {}.\".format(len(sentences)))\n",
    "print(\"Number of texts: {}.\".format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_features(w2v_model, sentence_group):\n",
    "    \"\"\" Transform a sentence_group (containing multiple lists\n",
    "    of words) into a feature vector. It averages out all the\n",
    "    word vectors of the sentence_group.\n",
    "    \"\"\"\n",
    "    words = np.concatenate(sentence_group)  # words in text\n",
    "    index2word_set = set(w2v_model.index_to_key) # set(w2v_model.wv.vocab.keys())  # words known to model\n",
    "    \n",
    "    featureVec = np.zeros(w2v_model.vector_size, dtype=\"float32\")\n",
    "    \n",
    "    # Initialize a counter for number of words in a review\n",
    "    nwords = 0\n",
    "    # Loop over each word in the comment and, if it is in the model's vocabulary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            featureVec = np.add(featureVec, w2v_model[word])\n",
    "            nwords += 1.\n",
    "\n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords > 0:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['w2v_features'] = list(map(lambda sen_group:\n",
    "                                     get_w2v_features(W2Vmodel, sen_group),\n",
    "                                     train_data.tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>document_sentences</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>w2v_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>[when the young people returned to the ballroo...</td>\n",
       "      <td>[[when, the, young, people, returned, to, the,...</td>\n",
       "      <td>[0.026869211, 0.050346404, 0.016655555, 0.0601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all through dinner time, mrs. fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>[all through dinner time, mrs,  fayre was some...</td>\n",
       "      <td>[[all, through, dinner, time, mrs], [fayre, wa...</td>\n",
       "      <td>[0.032734014, 0.028537542, 0.019979037, 0.1107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>[as roger had predicted, the snow departed as ...</td>\n",
       "      <td>[[as, roger, had, predicted, the, snow, depart...</td>\n",
       "      <td>[0.013358668, 0.034155294, 0.046266757, 0.0813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>[and outside before the palace a great garden ...</td>\n",
       "      <td>[[and, outside, before, the, palace, a, great,...</td>\n",
       "      <td>[0.05260147, 0.08936741, 0.016588992, 0.086939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>once upon a time there were three bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "      <td>[once upon a time there were three bears who l...</td>\n",
       "      <td>[[once, upon, a, time, there, were, three, bea...</td>\n",
       "      <td>[0.052981816, 0.027809488, 0.01056733, 0.14423...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  \\\n",
       "0  when the young people returned to the ballroom... -0.340259   \n",
       "1  all through dinner time, mrs. fayre was somewh... -0.315372   \n",
       "2  as roger had predicted, the snow departed as q... -0.580118   \n",
       "3  and outside before the palace a great garden w... -1.054013   \n",
       "4  once upon a time there were three bears who li...  0.247197   \n",
       "\n",
       "   standard_error                                 document_sentences  \\\n",
       "0        0.464009  [when the young people returned to the ballroo...   \n",
       "1        0.480805  [all through dinner time, mrs,  fayre was some...   \n",
       "2        0.476676  [as roger had predicted, the snow departed as ...   \n",
       "3        0.450007  [and outside before the palace a great garden ...   \n",
       "4        0.510845  [once upon a time there were three bears who l...   \n",
       "\n",
       "                                 tokenized_sentences  \\\n",
       "0  [[when, the, young, people, returned, to, the,...   \n",
       "1  [[all, through, dinner, time, mrs], [fayre, wa...   \n",
       "2  [[as, roger, had, predicted, the, snow, depart...   \n",
       "3  [[and, outside, before, the, palace, a, great,...   \n",
       "4  [[once, upon, a, time, there, were, three, bea...   \n",
       "\n",
       "                                        w2v_features  \n",
       "0  [0.026869211, 0.050346404, 0.016655555, 0.0601...  \n",
       "1  [0.032734014, 0.028537542, 0.019979037, 0.1107...  \n",
       "2  [0.013358668, 0.034155294, 0.046266757, 0.0813...  \n",
       "3  [0.05260147, 0.08936741, 0.016588992, 0.086939...  \n",
       "4  [0.052981816, 0.027809488, 0.01056733, 0.14423...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"w2v_resh_features\"] = train_data[\"w2v_features\"].apply(lambda x : x.reshape(1,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_w2v = train_data.w2v_resh_features[0]\n",
    "for i in range(1, len(train_data)):\n",
    "    arr_w2v = np.vstack((arr_w2v, train_data.w2v_resh_features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-940838da0b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mumap_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l1'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "umap_emb = umap.UMAP(n_neighbors= 15, n_components = 2, target_metric = 'l1' , n_epochs = 500).fit_transform(arr_w2v, y=train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'umap_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3236ab11e116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mumap_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Spectral'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfg_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'umap_emb' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*umap_emb.T, s=0.3, c=train_data.target, cmap='Spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "ax.patch.set_facecolor('black')\n",
    "fg_color = 'white'\n",
    "cbar = plt.colorbar()\n",
    "plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color=fg_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    arr_w2v, train_data.target, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = umap.UMAP(n_neighbors= 15, n_components = 2, target_metric = 'l1' , n_epochs = 1000).fit(X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embedding = mapper.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*mapper.embedding_.T, s=3, c=y_train, cmap='Spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "ax.patch.set_facecolor('black')\n",
    "fg_color = 'black'\n",
    "cbar = plt.colorbar()\n",
    "plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color=fg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*val_embedding.T, s=3, c=y_val, cmap='Spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "ax.patch.set_facecolor('black')\n",
    "fg_color = 'black'\n",
    "cbar = plt.colorbar()\n",
    "plt.setp(plt.getp(cbar.ax.axes, 'yticklabels'), color=fg_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression on W2V\n",
    "Proviamo a vedere se le feature del W2V sono rilevanti per-se "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y_val, y_pred) #0.44 not bad, let's see on test :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =  pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.excerpt = test_data['excerpt'].apply(str)\n",
    "non_ascii_words = remove_ascii_words(test_data)\n",
    "\n",
    "print(\"Replaced {} words with characters with an ordinal >= 128 in the test data.\".format(\n",
    "    len(non_ascii_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(test_data[test_data.tokenized_sentences.str.len() == 0].index, inplace= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with all sentences\n",
    "sentences_test = []\n",
    "for sentence_group in test_data.tokenized_sentences:\n",
    "    sentences_test.extend(sentence_group)\n",
    "\n",
    "print(\"Number of sentences: {}.\".format(len(sentences)))\n",
    "print(\"Number of texts: {}.\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['w2v_features'] = list(map(lambda sen_group:\n",
    "                                     get_w2v_features(W2Vmodel, sen_group),\n",
    "                                     test_data.tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"w2v_resh_features\"] = test_data[\"w2v_features\"].apply(lambda x : x.reshape(1,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_w2v_test = test_data.w2v_resh_features[0]\n",
    "for i in range(1, len(test_data)):\n",
    "    arr_w2v_test = np.vstack((arr_w2v_test, test_data.w2v_resh_features[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
