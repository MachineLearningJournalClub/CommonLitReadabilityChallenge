{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "junior-convergence",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-10T19:55:56.001907Z",
     "iopub.status.busy": "2021-06-10T19:55:56.000192Z",
     "iopub.status.idle": "2021-06-10T19:56:02.605344Z",
     "shell.execute_reply": "2021-06-10T19:56:02.604413Z",
     "shell.execute_reply.started": "2021-06-10T15:21:45.142691Z"
    },
    "papermill": {
     "duration": 6.638473,
     "end_time": "2021-06-10T19:56:02.605502",
     "exception": false,
     "start_time": "2021-06-10T19:55:55.967029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor, Pool, CatBoost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-filling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:02.662209Z",
     "iopub.status.busy": "2021-06-10T19:56:02.661677Z",
     "iopub.status.idle": "2021-06-10T19:56:02.748816Z",
     "shell.execute_reply": "2021-06-10T19:56:02.748376Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.867264Z"
    },
    "papermill": {
     "duration": 0.118885,
     "end_time": "2021-06-10T19:56:02.748946",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.630061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "\n",
    "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
    "\n",
    "target = train_data['target'].to_numpy()\n",
    "bins = train_data.bins.to_numpy()\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detailed-theorem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:02.803269Z",
     "iopub.status.busy": "2021-06-10T19:56:02.802649Z",
     "iopub.status.idle": "2021-06-10T19:56:02.809098Z",
     "shell.execute_reply": "2021-06-10T19:56:02.808209Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.950919Z"
    },
    "papermill": {
     "duration": 0.0354,
     "end_time": "2021-06-10T19:56:02.809205",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.773805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'nfolds':5,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blocked-investor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:02.862370Z",
     "iopub.status.busy": "2021-06-10T19:56:02.861580Z",
     "iopub.status.idle": "2021-06-10T19:56:02.863659Z",
     "shell.execute_reply": "2021-06-10T19:56:02.864117Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.962367Z"
    },
    "papermill": {
     "duration": 0.031204,
     "end_time": "2021-06-10T19:56:02.864235",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.833031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-indie",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:02.917689Z",
     "iopub.status.busy": "2021-06-10T19:56:02.916990Z",
     "iopub.status.idle": "2021-06-10T19:56:02.919563Z",
     "shell.execute_reply": "2021-06-10T19:56:02.919081Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.973364Z"
    },
    "papermill": {
     "duration": 0.031606,
     "end_time": "2021-06-10T19:56:02.919660",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.888054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "\n",
    "        score = self.V(att)\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "variable-publication",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:02.972626Z",
     "iopub.status.busy": "2021-06-10T19:56:02.971951Z",
     "iopub.status.idle": "2021-06-10T19:56:02.974219Z",
     "shell.execute_reply": "2021-06-10T19:56:02.974643Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.983550Z"
    },
    "papermill": {
     "duration": 0.031418,
     "end_time": "2021-06-10T19:56:02.974769",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.943351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n",
    "        self.head = AttentionHead(768,768,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.head.out_features,1)\n",
    "\n",
    "    def forward(self,**xb):\n",
    "        x = self.roberta(**xb)[0]\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-budapest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:03.029572Z",
     "iopub.status.busy": "2021-06-10T19:56:03.028857Z",
     "iopub.status.idle": "2021-06-10T19:56:03.031403Z",
     "shell.execute_reply": "2021-06-10T19:56:03.030921Z",
     "shell.execute_reply.started": "2021-06-10T15:21:51.993220Z"
    },
    "papermill": {
     "duration": 0.033238,
     "end_time": "2021-06-10T19:56:03.031498",
     "exception": false,
     "start_time": "2021-06-10T19:56:02.998260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n",
    "    \n",
    "    ds = CLRPDataset(df,tokenizer)\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "naval-workstation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:56:03.136027Z",
     "iopub.status.busy": "2021-06-10T19:56:03.135401Z",
     "iopub.status.idle": "2021-06-10T19:59:08.886859Z",
     "shell.execute_reply": "2021-06-10T19:59:08.886061Z",
     "shell.execute_reply.started": "2021-06-10T15:21:52.006194Z"
    },
    "papermill": {
     "duration": 185.831538,
     "end_time": "2021-06-10T19:59:08.887024",
     "exception": false,
     "start_time": "2021-06-10T19:56:03.055486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:23,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:22,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:21,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\n",
    "test_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')\n",
    "\n",
    "train_embeddings2 =  get_embeddings(train_data,'../input/clr-roberta/model1/model1.bin')\n",
    "test_embeddings2 = get_embeddings(test_data,'../input/clr-roberta/model1/model1.bin')\n",
    "\n",
    "train_embeddings3 =  get_embeddings(train_data,'../input/clr-roberta/model2/model2.bin')\n",
    "test_embeddings3 = get_embeddings(test_data,'../input/clr-roberta/model2/model2.bin')\n",
    "\n",
    "train_embeddings4 =  get_embeddings(train_data,'../input/clr-roberta/model3/model3.bin')\n",
    "test_embeddings4 = get_embeddings(test_data,'../input/clr-roberta/model3/model3.bin')\n",
    "\n",
    "train_embeddings5 =  get_embeddings(train_data,'../input/clr-roberta/model4/model4.bin')\n",
    "test_embeddings5 = get_embeddings(test_data,'../input/clr-roberta/model4/model4.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-promise",
   "metadata": {
    "papermill": {
     "duration": 0.064347,
     "end_time": "2021-06-10T19:59:09.017252",
     "exception": false,
     "start_time": "2021-06-10T19:59:08.952905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "narrative-paradise",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:59:09.155074Z",
     "iopub.status.busy": "2021-06-10T19:59:09.154168Z",
     "iopub.status.idle": "2021-06-10T19:59:09.156839Z",
     "shell.execute_reply": "2021-06-10T19:59:09.156290Z",
     "shell.execute_reply.started": "2021-06-10T15:25:01.658776Z"
    },
    "papermill": {
     "duration": 0.074972,
     "end_time": "2021-06-10T19:59:09.156947",
     "exception": false,
     "start_time": "2021-06-10T19:59:09.081975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = SVR(C=C,kernel=kernel,gamma='auto')\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "editorial-functionality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:59:09.289978Z",
     "iopub.status.busy": "2021-06-10T19:59:09.289440Z",
     "iopub.status.idle": "2021-06-10T19:59:50.883097Z",
     "shell.execute_reply": "2021-06-10T19:59:50.882287Z",
     "shell.execute_reply.started": "2021-06-10T15:25:01.671573Z"
    },
    "papermill": {
     "duration": 41.662874,
     "end_time": "2021-06-10T19:59:50.883308",
     "exception": false,
     "start_time": "2021-06-10T19:59:09.220434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.47727497027807975\n",
      "Fold 1 , rmse score: 0.2578880377682382\n",
      "Fold 2 , rmse score: 0.2541082644861084\n",
      "Fold 3 , rmse score: 0.24054325983483563\n",
      "Fold 4 , rmse score: 0.2551938404392728\n",
      "mean rmse 0.297001674561307\n",
      "Fold 0 , rmse score: 0.2425235616562364\n",
      "Fold 1 , rmse score: 0.5016510069411838\n",
      "Fold 2 , rmse score: 0.23847703706225037\n",
      "Fold 3 , rmse score: 0.23492862892763802\n",
      "Fold 4 , rmse score: 0.24930508381707772\n",
      "mean rmse 0.2933770636808773\n",
      "Fold 0 , rmse score: 0.3908661185328736\n",
      "Fold 1 , rmse score: 0.4135395361379846\n",
      "Fold 2 , rmse score: 0.4895740066653232\n",
      "Fold 3 , rmse score: 0.3756053322147557\n",
      "Fold 4 , rmse score: 0.4008420352519307\n",
      "mean rmse 0.4140854057605735\n",
      "Fold 0 , rmse score: 0.2878583154409844\n",
      "Fold 1 , rmse score: 0.27540087825175247\n",
      "Fold 2 , rmse score: 0.2809937810667762\n",
      "Fold 3 , rmse score: 0.45763179894261946\n",
      "Fold 4 , rmse score: 0.2852643347020617\n",
      "mean rmse 0.31742982168083883\n",
      "Fold 0 , rmse score: 0.4013671778501825\n",
      "Fold 1 , rmse score: 0.4266264148954528\n",
      "Fold 2 , rmse score: 0.4028700034689983\n",
      "Fold 3 , rmse score: 0.3969900356101473\n",
      "Fold 4 , rmse score: 0.5105196639952477\n",
      "mean rmse 0.4276746591640057\n"
     ]
    }
   ],
   "source": [
    "svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n",
    "svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n",
    "svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n",
    "svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n",
    "svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "employed-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T19:59:51.065006Z",
     "iopub.status.busy": "2021-06-10T19:59:51.063287Z",
     "iopub.status.idle": "2021-06-10T20:00:03.379707Z",
     "shell.execute_reply": "2021-06-10T20:00:03.379213Z",
     "shell.execute_reply.started": "2021-06-10T15:25:43.558428Z"
    },
    "papermill": {
     "duration": 12.425768,
     "end_time": "2021-06-10T20:00:03.379861",
     "exception": false,
     "start_time": "2021-06-10T19:59:50.954093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Processing /kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from pyflagser) (1.5.4)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from pyflagser) (1.19.5)\r\n",
      "Installing collected packages: pyflagser\r\n",
      "Successfully installed pyflagser-0.4.4\r\n",
      "Looking in links: file:///kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Processing /kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: plotly>=4.8.2 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (4.14.3)\r\n",
      "Requirement already satisfied: python-igraph>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.9.1)\r\n",
      "Requirement already satisfied: pyflagser>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.4.4)\r\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (7.6.3)\r\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.19.5)\r\n",
      "Requirement already satisfied: joblib>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.0.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (0.24.1)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from giotto-tda) (1.5.4)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.1.2)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (3.5.1)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.0.5)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (1.0.0)\r\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (7.22.0)\r\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5.1->giotto-tda) (5.5.0)\r\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.1)\r\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.1.12)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (3.0.18)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.5)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.18.0)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (2.8.1)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.8.0)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.8.1)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (0.2.0)\r\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (4.7.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.2.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.4.0)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (1.15.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (0.17.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (20.3.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.0)\r\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.8.2->giotto-tda) (1.3.3)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.5)\r\n",
      "Requirement already satisfied: texttable>=1.6.2 in /opt/conda/lib/python3.7/site-packages (from python-igraph>=0.8.2->giotto-tda) (1.6.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.1->giotto-tda) (2.1.0)\r\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (6.3.0)\r\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (20.1.0)\r\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.9.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.5.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.11.3)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.9.3)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (22.0.3)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (6.0.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (2.8.1)\r\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.14.5)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.20)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->giotto-tda) (3.7.4.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.1.1)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.4.4)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.8.4)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (3.3.0)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.1.2)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.4.2)\r\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.3)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.5.3)\r\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.7.1)\r\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.10)\r\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (1.4.3)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (0.5.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (20.9)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->giotto-tda) (2.4.7)\r\n",
      "Installing collected packages: giotto-tda\r\n",
      "Successfully installed giotto-tda-0.4.0\r\n"
     ]
    }
   ],
   "source": [
    "#library for topological data analysis\n",
    "!pip install pyflagser --no-index --find-links=file:///kaggle/input/roberta/pyflagser-0.4.4-cp37-cp37m-manylinux2010_x86_64.whl\n",
    "!pip install giotto-tda --no-index --find-links=file:///kaggle/input/roberta/giotto_tda-0.4.0-cp37-cp37m-manylinux2010_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prime-perception",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:00:03.537200Z",
     "iopub.status.busy": "2021-06-10T20:00:03.535805Z",
     "iopub.status.idle": "2021-06-10T20:00:03.578359Z",
     "shell.execute_reply": "2021-06-10T20:00:03.577933Z",
     "shell.execute_reply.started": "2021-06-10T15:25:56.120249Z"
    },
    "papermill": {
     "duration": 0.123172,
     "end_time": "2021-06-10T20:00:03.578479",
     "exception": false,
     "start_time": "2021-06-10T20:00:03.455307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#giotto-tda , topological features extraction\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Amplitude, NumberOfPoints, PersistenceEntropy\n",
    "\n",
    "def extract_features(X, time_delay=1, dimension=1, stride=10, h_dim=(0,1), n_jobs=-1):\n",
    "    \n",
    "    samples = X\n",
    "    \n",
    "    TE = TakensEmbedding(time_delay=time_delay, dimension=dimension, stride=stride)   \n",
    "    te = TE.fit_transform(samples)\n",
    "        \n",
    "    VR = VietorisRipsPersistence(homology_dimensions=h_dim, n_jobs=n_jobs)\n",
    "    X_vr = VR.fit_transform(te)\n",
    "    \n",
    "    X_features = []\n",
    "    \n",
    "    #amplitude\n",
    "    metrics =  ['bottleneck','wasserstein', 'betti', 'landscape', 'silhouette', 'heat']\n",
    "    for metric in metrics:\n",
    "        Ampl = Amplitude(metric=metric, n_jobs=n_jobs)\n",
    "        X_a = Ampl.fit_transform(X_vr)\n",
    "        X_features.append(X_a[:,0])\n",
    "        #X_features.append(X_a[:,1])\n",
    "        \n",
    "    #entropy\n",
    "    PE = PersistenceEntropy(normalize=True, nan_fill_value=-1, n_jobs=n_jobs)\n",
    "    X_pe = PE.fit_transform(X_vr)\n",
    "    \n",
    "    X_features.append(X_pe[:,0])\n",
    "    #X_features.append(X_pe[:,1])\n",
    "\n",
    "    PE = PersistenceEntropy(normalize=False, nan_fill_value=-1, n_jobs=n_jobs)\n",
    "    X_pe = PE.fit_transform(X_vr)\n",
    "\n",
    "    X_features.append(X_pe[:,0])\n",
    "    #X_features.append(X_pe[:,1])\n",
    "\n",
    "    #number of points\n",
    "    #NOP = NumberOfPoints(n_jobs=n_jobs)\n",
    "    #X_nop = NOP.fit_transform(X_vr)\n",
    "\n",
    "    #X_features.append(X_nop[:,0])\n",
    "    #X_features.append(X_nop[:,1])\n",
    "    \n",
    "    X_features = np.array(X_features).T\n",
    "      \n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seventh-starter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:00:03.729921Z",
     "iopub.status.busy": "2021-06-10T20:00:03.729123Z",
     "iopub.status.idle": "2021-06-10T20:12:44.852718Z",
     "shell.execute_reply": "2021-06-10T20:12:44.853509Z",
     "shell.execute_reply.started": "2021-06-10T15:25:56.180278Z"
    },
    "papermill": {
     "duration": 761.20216,
     "end_time": "2021-06-10T20:12:44.853772",
     "exception": false,
     "start_time": "2021-06-10T20:00:03.651612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tda_features_train1 = extract_features(train_embeddings1, stride = 2)\n",
    "tda_features_test1 = extract_features(test_embeddings1, stride = 2)\n",
    "\n",
    "tda_features_train2 = extract_features(train_embeddings2, stride = 2)\n",
    "tda_features_test2 = extract_features(test_embeddings2, stride = 2)\n",
    "\n",
    "tda_features_train3 = extract_features(train_embeddings3, stride = 2)\n",
    "tda_features_test3 = extract_features(test_embeddings3, stride = 2)\n",
    "\n",
    "tda_features_train4 = extract_features(train_embeddings4, stride = 2)\n",
    "tda_features_test4 = extract_features(test_embeddings4, stride = 2)\n",
    "\n",
    "tda_features_train5 = extract_features(train_embeddings5, stride = 2)\n",
    "tda_features_test5 = extract_features(test_embeddings5, stride = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "leading-mailing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:12:45.007154Z",
     "iopub.status.busy": "2021-06-10T20:12:45.006347Z",
     "iopub.status.idle": "2021-06-10T20:12:45.015646Z",
     "shell.execute_reply": "2021-06-10T20:12:45.016092Z",
     "shell.execute_reply.started": "2021-06-10T15:38:38.581611Z"
    },
    "papermill": {
     "duration": 0.08761,
     "end_time": "2021-06-10T20:12:45.016221",
     "exception": false,
     "start_time": "2021-06-10T20:12:44.928611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard scaler on tda features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(tda_features_train1)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(tda_features_train2)\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(tda_features_train3)\n",
    "\n",
    "scaler4 = StandardScaler()\n",
    "scaler4.fit(tda_features_train4)\n",
    "\n",
    "scaler5 = StandardScaler()\n",
    "scaler5.fit(tda_features_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "studied-fitting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:12:45.167981Z",
     "iopub.status.busy": "2021-06-10T20:12:45.167105Z",
     "iopub.status.idle": "2021-06-10T20:12:45.172051Z",
     "shell.execute_reply": "2021-06-10T20:12:45.171611Z",
     "shell.execute_reply.started": "2021-06-10T15:38:38.605455Z"
    },
    "papermill": {
     "duration": 0.082374,
     "end_time": "2021-06-10T20:12:45.172159",
     "exception": false,
     "start_time": "2021-06-10T20:12:45.089785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tda_train_norm1 = scaler1.transform(tda_features_train1)\n",
    "tda_test_norm1 = scaler1.transform(tda_features_test1)\n",
    "\n",
    "tda_train_norm2 = scaler2.transform(tda_features_train2)\n",
    "tda_test_norm2 = scaler2.transform(tda_features_test2)\n",
    "\n",
    "tda_train_norm3 = scaler3.transform(tda_features_train3)\n",
    "tda_test_norm3 = scaler3.transform(tda_features_test3)\n",
    "\n",
    "tda_train_norm4 = scaler4.transform(tda_features_train4)\n",
    "tda_test_norm4 = scaler4.transform(tda_features_test4)\n",
    "\n",
    "tda_train_norm5 = scaler5.transform(tda_features_train5)\n",
    "tda_test_norm5 = scaler5.transform(tda_features_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charitable-austria",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:12:45.325694Z",
     "iopub.status.busy": "2021-06-10T20:12:45.325187Z",
     "iopub.status.idle": "2021-06-10T20:13:02.853987Z",
     "shell.execute_reply": "2021-06-10T20:13:02.853513Z",
     "shell.execute_reply.started": "2021-06-10T15:38:38.625894Z"
    },
    "papermill": {
     "duration": 17.609438,
     "end_time": "2021-06-10T20:13:02.854117",
     "exception": false,
     "start_time": "2021-06-10T20:12:45.244679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.404787\tvalid_1's rmse: 0.50171\n",
      "[20000]\ttraining's rmse: 0.404282\tvalid_1's rmse: 0.501281\n",
      "[30000]\ttraining's rmse: 0.404282\tvalid_1's rmse: 0.501281\n",
      "[40000]\ttraining's rmse: 0.404282\tvalid_1's rmse: 0.501281\n",
      "Early stopping, best iteration is:\n",
      "[48361]\ttraining's rmse: 0.404282\tvalid_1's rmse: 0.501281\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.408614\tvalid_1's rmse: 0.505876\n",
      "[20000]\ttraining's rmse: 0.407509\tvalid_1's rmse: 0.505058\n",
      "[30000]\ttraining's rmse: 0.407509\tvalid_1's rmse: 0.505056\n",
      "Early stopping, best iteration is:\n",
      "[31968]\ttraining's rmse: 0.407509\tvalid_1's rmse: 0.505056\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.416634\tvalid_1's rmse: 0.415634\n",
      "Early stopping, best iteration is:\n",
      "[11772]\ttraining's rmse: 0.415705\tvalid_1's rmse: 0.415267\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6971]\ttraining's rmse: 0.416396\tvalid_1's rmse: 0.430072\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.408006\tvalid_1's rmse: 0.450026\n",
      "Early stopping, best iteration is:\n",
      "[11774]\ttraining's rmse: 0.406955\tvalid_1's rmse: 0.449536\n"
     ]
    }
   ],
   "source": [
    "### LightGBM on Top Features \n",
    "\n",
    "# lgbm on topological features\n",
    "lgbm_preds_tda1 = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm1[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm1[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda1 += lgb_model.predict(tda_test_norm1)/nfolds\n",
    "    \n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "appointed-measurement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:03.018015Z",
     "iopub.status.busy": "2021-06-10T20:13:03.017191Z",
     "iopub.status.idle": "2021-06-10T20:13:16.131890Z",
     "shell.execute_reply": "2021-06-10T20:13:16.131394Z",
     "shell.execute_reply.started": "2021-06-10T15:38:57.262372Z"
    },
    "papermill": {
     "duration": 13.200042,
     "end_time": "2021-06-10T20:13:16.132046",
     "exception": false,
     "start_time": "2021-06-10T20:13:02.932004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.502021\tvalid_1's rmse: 0.656131\n",
      "Early stopping, best iteration is:\n",
      "[11728]\ttraining's rmse: 0.501561\tvalid_1's rmse: 0.655667\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8587]\ttraining's rmse: 0.503213\tvalid_1's rmse: 0.639628\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.53403\tvalid_1's rmse: 0.491294\n",
      "Early stopping, best iteration is:\n",
      "[11427]\ttraining's rmse: 0.532508\tvalid_1's rmse: 0.490417\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.528062\tvalid_1's rmse: 0.517515\n",
      "Early stopping, best iteration is:\n",
      "[11380]\ttraining's rmse: 0.526618\tvalid_1's rmse: 0.517124\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8814]\ttraining's rmse: 0.510829\tvalid_1's rmse: 0.596892\n"
     ]
    }
   ],
   "source": [
    "# lgbm on topological features\n",
    "lgbm_preds_tda2 = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm2[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm2[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda2 += lgb_model.predict(tda_test_norm2)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "occupational-substance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:16.302362Z",
     "iopub.status.busy": "2021-06-10T20:13:16.301601Z",
     "iopub.status.idle": "2021-06-10T20:13:25.365234Z",
     "shell.execute_reply": "2021-06-10T20:13:25.364728Z",
     "shell.execute_reply.started": "2021-06-10T15:39:10.591541Z"
    },
    "papermill": {
     "duration": 9.151737,
     "end_time": "2021-06-10T20:13:25.365363",
     "exception": false,
     "start_time": "2021-06-10T20:13:16.213626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4414]\ttraining's rmse: 0.538014\tvalid_1's rmse: 0.656611\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.542316\tvalid_1's rmse: 0.629098\n",
      "Early stopping, best iteration is:\n",
      "[10688]\ttraining's rmse: 0.542072\tvalid_1's rmse: 0.628995\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6103]\ttraining's rmse: 0.553817\tvalid_1's rmse: 0.562122\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6898]\ttraining's rmse: 0.552445\tvalid_1's rmse: 0.559584\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6620]\ttraining's rmse: 0.53712\tvalid_1's rmse: 0.633589\n"
     ]
    }
   ],
   "source": [
    "# lgbm on topological features\n",
    "lgbm_preds_tda3 = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm3[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm3[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda3 += lgb_model.predict(tda_test_norm3)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fluid-consent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:25.540006Z",
     "iopub.status.busy": "2021-06-10T20:13:25.539219Z",
     "iopub.status.idle": "2021-06-10T20:13:36.597186Z",
     "shell.execute_reply": "2021-06-10T20:13:36.596290Z",
     "shell.execute_reply.started": "2021-06-10T15:39:20.101611Z"
    },
    "papermill": {
     "duration": 11.148348,
     "end_time": "2021-06-10T20:13:36.597341",
     "exception": false,
     "start_time": "2021-06-10T20:13:25.448993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9075]\ttraining's rmse: 0.572141\tvalid_1's rmse: 0.789692\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.601167\tvalid_1's rmse: 0.683834\n",
      "Early stopping, best iteration is:\n",
      "[9263]\ttraining's rmse: 0.601181\tvalid_1's rmse: 0.683826\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8286]\ttraining's rmse: 0.605616\tvalid_1's rmse: 0.650489\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6638]\ttraining's rmse: 0.617769\tvalid_1's rmse: 0.621675\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8526]\ttraining's rmse: 0.593702\tvalid_1's rmse: 0.671693\n"
     ]
    }
   ],
   "source": [
    "# lgbm on topological features\n",
    "lgbm_preds_tda4 = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm4[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm4[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda4 += lgb_model.predict(tda_test_norm4)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greatest-division",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:36.785709Z",
     "iopub.status.busy": "2021-06-10T20:13:36.784948Z",
     "iopub.status.idle": "2021-06-10T20:13:45.879250Z",
     "shell.execute_reply": "2021-06-10T20:13:45.880293Z",
     "shell.execute_reply.started": "2021-06-10T15:39:32.040563Z"
    },
    "papermill": {
     "duration": 9.188835,
     "end_time": "2021-06-10T20:13:45.880510",
     "exception": false,
     "start_time": "2021-06-10T20:13:36.691675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.515625\tvalid_1's rmse: 0.626008\n",
      "Early stopping, best iteration is:\n",
      "[11538]\ttraining's rmse: 0.515612\tvalid_1's rmse: 0.625981\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[10000]\ttraining's rmse: 0.530877\tvalid_1's rmse: 0.575071\n",
      "Early stopping, best iteration is:\n",
      "[11924]\ttraining's rmse: 0.529506\tvalid_1's rmse: 0.574773\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3866]\ttraining's rmse: 0.541741\tvalid_1's rmse: 0.538031\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2808]\ttraining's rmse: 0.544336\tvalid_1's rmse: 0.587953\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6396]\ttraining's rmse: 0.522228\tvalid_1's rmse: 0.615413\n"
     ]
    }
   ],
   "source": [
    "# lgbm on topological features\n",
    "lgbm_preds_tda5 = np.zeros(test_data.shape[0])\n",
    "\n",
    "params = {\n",
    " 'reg_alpha': 6.147694913504962,\n",
    " 'reg_lambda': 0.002457826062076097,\n",
    " 'colsample_bytree': 0.3,\n",
    " 'subsample': 0.8,\n",
    " 'learning_rate': 1e-2,\n",
    " 'max_depth': 20,\n",
    " 'num_leaves': 111,\n",
    " 'min_child_samples': 285,\n",
    " 'random_state': 42,\n",
    " 'verbose':-1,\n",
    " 'n_estimators': 160000,\n",
    " 'metric': 'rmse',\n",
    " 'cat_smooth': 39}\n",
    "\n",
    "nfolds=5\n",
    "kfold = StratifiedKFold(n_splits=nfolds)\n",
    "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['bins'])):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(tda_train_norm5[train_idx],target[train_idx].ravel())\n",
    "    lgb_valid = lgb.Dataset(tda_train_norm5[valid_idx],target[valid_idx].ravel())\n",
    "    \n",
    "    lgb_model = lgb.train(params,\n",
    "                      lgb_train, \n",
    "                      valid_sets=[lgb_train,lgb_valid],\n",
    "                      verbose_eval=10000,\n",
    "                      early_stopping_rounds=800,\n",
    "                      )\n",
    "\n",
    "    lgbm_preds_tda5 += lgb_model.predict(tda_test_norm5)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "israeli-threshold",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:46.192424Z",
     "iopub.status.busy": "2021-06-10T20:13:46.191609Z",
     "iopub.status.idle": "2021-06-10T20:13:46.194668Z",
     "shell.execute_reply": "2021-06-10T20:13:46.194243Z",
     "shell.execute_reply.started": "2021-06-10T15:39:49.988189Z"
    },
    "papermill": {
     "duration": 0.165654,
     "end_time": "2021-06-10T20:13:46.194802",
     "exception": false,
     "start_time": "2021-06-10T20:13:46.029148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_preds = 0.75*(svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5 + 0.25*(lgbm_preds_tda1+ lgbm_preds_tda2 + lgbm_preds_tda3 + lgbm_preds_tda4 + lgbm_preds_tda5 )/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-boring",
   "metadata": {
    "papermill": {
     "duration": 0.089841,
     "end_time": "2021-06-10T20:13:46.377659",
     "exception": false,
     "start_time": "2021-06-10T20:13:46.287818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The second notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "opponent-presentation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:46.562272Z",
     "iopub.status.busy": "2021-06-10T20:13:46.561631Z",
     "iopub.status.idle": "2021-06-10T20:13:46.564554Z",
     "shell.execute_reply": "2021-06-10T20:13:46.564987Z"
    },
    "papermill": {
     "duration": 0.098319,
     "end_time": "2021-06-10T20:13:46.565130",
     "exception": false,
     "start_time": "2021-06-10T20:13:46.466811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "animated-partnership",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:46.781287Z",
     "iopub.status.busy": "2021-06-10T20:13:46.780707Z",
     "iopub.status.idle": "2021-06-10T20:13:51.436834Z",
     "shell.execute_reply": "2021-06-10T20:13:51.436290Z"
    },
    "papermill": {
     "duration": 4.782471,
     "end_time": "2021-06-10T20:13:51.436984",
     "exception": false,
     "start_time": "2021-06-10T20:13:46.654513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "operating-domestic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:51.647945Z",
     "iopub.status.busy": "2021-06-10T20:13:51.646267Z",
     "iopub.status.idle": "2021-06-10T20:13:51.648877Z",
     "shell.execute_reply": "2021-06-10T20:13:51.649306Z"
    },
    "papermill": {
     "duration": 0.109589,
     "end_time": "2021-06-10T20:13:51.649450",
     "exception": false,
     "start_time": "2021-06-10T20:13:51.539861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spread-positive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:51.855512Z",
     "iopub.status.busy": "2021-06-10T20:13:51.854592Z",
     "iopub.status.idle": "2021-06-10T20:13:51.857424Z",
     "shell.execute_reply": "2021-06-10T20:13:51.856994Z"
    },
    "papermill": {
     "duration": 0.109427,
     "end_time": "2021-06-10T20:13:51.857545",
     "exception": false,
     "start_time": "2021-06-10T20:13:51.748118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regulation-humanitarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:52.060478Z",
     "iopub.status.busy": "2021-06-10T20:13:52.059598Z",
     "iopub.status.idle": "2021-06-10T20:13:52.062370Z",
     "shell.execute_reply": "2021-06-10T20:13:52.061883Z"
    },
    "papermill": {
     "duration": 0.109767,
     "end_time": "2021-06-10T20:13:52.062483",
     "exception": false,
     "start_time": "2021-06-10T20:13:51.952716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "social-yield",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:52.250546Z",
     "iopub.status.busy": "2021-06-10T20:13:52.249501Z",
     "iopub.status.idle": "2021-06-10T20:13:52.252260Z",
     "shell.execute_reply": "2021-06-10T20:13:52.251861Z"
    },
    "papermill": {
     "duration": 0.098235,
     "end_time": "2021-06-10T20:13:52.252387",
     "exception": false,
     "start_time": "2021-06-10T20:13:52.154152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thermal-fence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:52.440801Z",
     "iopub.status.busy": "2021-06-10T20:13:52.439376Z",
     "iopub.status.idle": "2021-06-10T20:13:52.441389Z",
     "shell.execute_reply": "2021-06-10T20:13:52.442270Z"
    },
    "papermill": {
     "duration": 0.100537,
     "end_time": "2021-06-10T20:13:52.442412",
     "exception": false,
     "start_time": "2021-06-10T20:13:52.341875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "progressive-cathedral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:52.628119Z",
     "iopub.status.busy": "2021-06-10T20:13:52.627401Z",
     "iopub.status.idle": "2021-06-10T20:13:52.631120Z",
     "shell.execute_reply": "2021-06-10T20:13:52.630696Z"
    },
    "papermill": {
     "duration": 0.099749,
     "end_time": "2021-06-10T20:13:52.631235",
     "exception": false,
     "start_time": "2021-06-10T20:13:52.531486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "premium-marker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:52.816509Z",
     "iopub.status.busy": "2021-06-10T20:13:52.815836Z",
     "iopub.status.idle": "2021-06-10T20:13:52.819202Z",
     "shell.execute_reply": "2021-06-10T20:13:52.818792Z"
    },
    "papermill": {
     "duration": 0.098519,
     "end_time": "2021-06-10T20:13:52.819318",
     "exception": false,
     "start_time": "2021-06-10T20:13:52.720799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sapphire-encoding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:13:53.009838Z",
     "iopub.status.busy": "2021-06-10T20:13:53.009007Z",
     "iopub.status.idle": "2021-06-10T20:18:41.366384Z",
     "shell.execute_reply": "2021-06-10T20:18:41.366946Z"
    },
    "papermill": {
     "duration": 288.458001,
     "end_time": "2021-06-10T20:18:41.367155",
     "exception": false,
     "start_time": "2021-06-10T20:13:52.909154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 1/5 [01:08<04:33, 68.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 2/5 [02:02<03:00, 60.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 3/5 [02:56<01:54, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 4/5 [03:53<00:57, 57.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [04:48<00:00, 57.66s/it]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "\n",
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accessory-flavor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-10T20:18:41.567233Z",
     "iopub.status.busy": "2021-06-10T20:18:41.566625Z",
     "iopub.status.idle": "2021-06-10T20:18:41.627538Z",
     "shell.execute_reply": "2021-06-10T20:18:41.627125Z"
    },
    "papermill": {
     "duration": 0.164765,
     "end_time": "2021-06-10T20:18:41.627655",
     "exception": false,
     "start_time": "2021-06-10T20:18:41.462890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample['target'] = (pred_df2.mean(axis=1)*0.35) + (pred_df1.mean(axis=1)*0.20) + (pred_df3.mean(axis=1) * 0.15) + (svm_preds * 0.30)\n",
    "sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-assurance",
   "metadata": {
    "papermill": {
     "duration": 0.096985,
     "end_time": "2021-06-10T20:18:41.825151",
     "exception": false,
     "start_time": "2021-06-10T20:18:41.728166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-settlement",
   "metadata": {
    "papermill": {
     "duration": 0.094986,
     "end_time": "2021-06-10T20:18:42.015265",
     "exception": false,
     "start_time": "2021-06-10T20:18:41.920279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1376.017985,
   "end_time": "2021-06-10T20:18:45.192433",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-10T19:55:49.174448",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
